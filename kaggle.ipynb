{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Кириленко Елена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import uniform_filter\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "import tqdm \n",
    "from tqdm import tqdm_notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем данные из файла в 2 массива в зависимости от типа картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во картинок indoor:  4702\n",
      "Кол-во картинок outdoor:  2203\n"
     ]
    }
   ],
   "source": [
    "indoor = []\n",
    "outdoor = []\n",
    "\n",
    "for n in range(6708):\n",
    "    try:\n",
    "        image = scipy.misc.imread('data/train/indoor_' + str(n) + '.jpg')\n",
    "        indoor.append(image)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for n in range(3157):\n",
    "    try:\n",
    "        image = scipy.misc.imread('data/train/outdoor_' + str(n) + '.jpg')\n",
    "        outdoor.append(image)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "indoor = np.array(indoor)\n",
    "outdoor = np.array(outdoor)\n",
    "print('Кол-во картинок indoor: ', len(indoor))\n",
    "print('Кол-во картинок outdoor: ', len(outdoor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем тестовые картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во картинок test:  2960\n"
     ]
    }
   ],
   "source": [
    "preliminary_test_images = []\n",
    "\n",
    "for n in range(2960):\n",
    "    try:\n",
    "        image = scipy.misc.imread('data/test/img_' + str(n) + '.jpg')\n",
    "        preliminary_test_images.append(image)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "preliminary_test_images = np.array(preliminary_test_images)\n",
    "print('Кол-во картинок test: ', len(preliminary_test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на наши картинки (первые из классов indoor, outdoor и test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x87ExbJdSOwDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132219588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e60c128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXl0nOWR7p/qbu2StdqykOUNG4NZbBzBsNgkYBZDmECS\nw5aEkDkEkxlg4txhC0sg5M6wZLu5c+6Q2GHHISFhCSEwxHhYhoRNNgbvK94tyZa1L93q7rp/dPte\nId7ns7ClluGt3zk+lupRfd/bn7r0db/VVSWqCsMw/CM03AswDGN4sOA3DE+x4DcMT7HgNwxPseA3\nDE+x4DcMT7HgNwxPseD3EBHZLCJnHuQxviUibwzWmozMY8FvGJ5iwe8ZIvIYgLEA/iQiHSJyo4ic\nJCJ/E5EWEXlfRL7Q5+e/JSKbRKRdRD4Uka+LyFEAfgng5PQxWobp4RgHgdjHe/1DRDYD+Laqviwi\n1QA+AHA5gP8EMBvAbwEcCaALwC4AJ6jqWhGpAlCmqitF5FvpY8wcjsdgHDx25ze+AeAFVX1BVZOq\nughAHYDz0noSwDEikqequ1R15bCt1BhULPiNcQAuSr/kb0m/hJ8JoEpVOwFcAuA7AHaJyJ9F5Mjh\nXKwxeFjw+0nf93rbADymqiV9/hWo6j0AoKovqepZAKoArAGwwHEM41OIBb+fNACYmP76cQB/LyLn\niEhYRHJF5AsiMkZEKkXkAhEpABAF0IHU24B9xxgjItmZX74xGFjw+8ndAG5Lv8S/BMAFAG4BsBup\nVwI3IPXcCAH4HwB2AtgL4PMA/jF9jP8CsBJAvYjsyejqjUHBdvsNw1Pszm8YnmLBbxieYsFvGJ5i\nwW8YnhLJ5MlKSkv0sMMOc2rJgLRxMpl02kWF+mRFeAaKHW9/64C4NQnwiXV3BxyPSzm5OVQLhfjf\n7N27dzvt5eUVfBnCFxIK0IRcDwCAuq9x0P5yMhGgJYM2pvnvs625yWkPhfjj2tvMSxVGV1VTrYlc\newAozM2lWm8s6rSHs3l4FpWVOu31jXvR2toR8Mz6/xxU8IvIHAC/ABAG8Ot9HwxhHHbYYXj8t485\ntW6NU7/27i6nPTfBA6SqhP+SurrdFxsAusI9VJMs9xqzkjHqs2k5/zRsKEwlTD5yEtXyCvgftl/9\n8pdO++VXXEl9wjl5/FwR/ocmO8wft8Td1zHOLz3a27jW1cXPFVH+B/bFZx912gty+MX/zdN/otot\nt36Pao/8x3yqnTJ1MtUatm9y2gtrRlGfMy75stP+nXk/oT79OeCX/SISBvB/AJwLYCqAy0Rk6oEe\nzzCMzHIw7/lPBLBBVTepagypSrALBmdZhmEMNQcT/NVIfRpsH9vTto8gInNFpE5E6pqbmw/idIZh\nDCZDvtuvqvNVtVZVa0tL3ZsUhmFknoMJ/h0Aavp8PyZtMwzjU8DB7Pa/C2CyiExAKugvBfC1IAcR\nQVZOllOLdvId24qCfKc9HOd/u7pjrVRLRPhOb14e30mfNHGi097dzOtauhobqVZcWkS1jhZ3igoA\nfngzT6rU1tY67eEET5VlZ/M0VH4uf4r0xvgxIznubFMsyrMpkTA/XmFAhqOliV//vc3u58Fp582h\nPk88+RzV3n/vHarNmMH3u19/ZTHVph17lNM+6wy+xuxcd+pWQgMP6QMOflWNi8i1AF5CKtX3oHV5\nMYxPDweV51fVFwC8MEhrMQwjg9jHew3DUyz4DcNTLPgNw1Ms+A3DUzJa1ScCsHqKZEABSSjR67SX\nFJdQn0huAdXC+Vxr6+qkWv3ObU77W6++Qn1mHMPTP4kYT28WhXk68s4bb+DHTLqvY47w40lAGlAT\nvGIuEuaFVXGyjog70wsA6OzlKbvegBThiEKeBqyuHuO0v/bq36jP6afOotq29auo1tjAP+YSRcD6\nR1c57ROPnkF9pMD9gbmsLJ627Y/d+Q3DUyz4DcNTLPgNw1Ms+A3DUyz4DcNTMrrbv3H9enxlzhed\n2o9/dh/120F22c/4/GnUp7S4kGqhgB3nRAEXcwuKnfapxx9LfZa+9RbVmrdtpdqRE8dRrWzUSKpJ\nnrtYqDdg114Ciqoiubz4KBlQRBLtdbc8iyCgqConoO9igq+xO8q1+3/lbuN16/euoT6b166h2p4d\nH1ItO48/tr0J3oas5gh3Yc/Opg7qc8zE6U57OKB3ZX/szm8YnmLBbxieYsFvGJ5iwW8YnmLBbxie\nYsFvGJ6S0VRfojeO5np3b7qNazZSv7ffe9Npn3nKidTnjtu+T7XvXc8LY0KlvFiotcudvqoP6Le3\nZh0vBMkKGAv1yvrVVGsJSBt9/TvXOu3ay32yld8Dop083ZRTGJAGjLqLsXoCCnTiAenIcIQXrKxY\nuoxqVdXuApiqSj6+bMta94QoAJgwbjTVdgT0axxTM5Zr4w932k+ZxVPZSlKw4YD+lP2xO79heIoF\nv2F4igW/YXiKBb9heIoFv2F4igW/YXhKRlN9I4pLMOesc5zarxc8TP0Wvfxnp729cy/1+do3+OSw\nMeM/Nkz4//Hsi/9JtZopR7iPV11JfWIBablQKEG1zh7eSzCSl0e1ts42pz2cx/sWSsI9WgsANMbv\nDzs/5OnZEOnJ+ON7f0x9brjhJqoVFvNKxlmzz6ba/Pv/3WmXUEDqM+xO6QJAVwdPz0YiPJz27OYT\nqivK3I8tksd7JJIWieC/ScfxP8HPfvxEIpsBtANIAIirqntQnGEYhxyDcec/XVV521XDMA5J7D2/\nYXjKwQa/AnhZRJaIyFzXD4jIXBGpE5G6nmj0IE9nGMZgcbAv+2eq6g4RGQVgkYisUdXX+/6Aqs4H\nMB8AKsrK+HQIwzAyykHd+VV1R/r/RgDPAOCVNoZhHFIc8J1fRAoAhFS1Pf312QDuCjxZdjYqxtY4\ntevPnE39lGRlNMkTG4kQrxD7r1cXUe2vr75MtXOL8p328pFl1OeoKROo9v4bf6VaEjwN2BNQaZct\n7scdEZ6+ikZbqbZm0waq/fmF56jW1uZOw9ZU88akoYDxX4kAbfSYw6jGiPYEVCvm8Cau+fnu5wAA\nJEL8Ghfl8/tscZ47DOPkGgJABwndRIKvoT8H87K/EsAzIrLvOL9RVZ4kNwzjkOKAg19VNwGYNohr\nMQwjg1iqzzA8xYLfMDzFgt8wPMWC3zA8JcNVfSNw5hx3BVZemDcefGHRS077hEm8Oi87h3+eKNbO\nU1ufO8pduQcA0RZ3g8Z3Vi2lPmuXL+fHC0jZxTp5E8muXp7GbGt2p4fuvP0H1KcgYEZe7fSZVKsK\nmBlYM7rcaW/Y4646BIDeXnfTTwCoqeLpvBEjePptZGWV065xnibOifC0YmUlr+Dcu57P+PvGZZdQ\nrb15h9P+9u9XUp8tu9ud9j2Nu6lPf+zObxieYsFvGJ5iwW8YnmLBbxieYsFvGJ6S0d3+SDiC8nL3\n+CQB38E+58K/d9rXrOS77D1tfCe9fXs91bKFF9REYu4d+GeeXEh9Wut5cca5p/BiprqNS6i2qYk3\nTnruueed9gnVPDMyMpvvlq9ZtZZq2RG+Y15a5h4npWH+lBPwopSebp4l+PWTj1CtapR7tx/Ki3c6\nO3h/vyMm80KtsnLeWzEkvCfjO2++4rSf+PmLqM+0Ge4CuYcf/wP1+diaBvyThmF8prDgNwxPseA3\nDE+x4DcMT7HgNwxPseA3DE/JaKovHA6hqMg9Nqq0pJj6FeS7C09i3T3UJ9bMU0OJjm6qxeM8JVNY\n6F7H3m07qU/1aJ4aKinhxSrHn8Cvx963ee+/+gZ3wceYMt5nMD+nkGrl5XzM14KHHqRaR4e7eGre\nvH+mPvEeXszUtttd/AIAU6dMolq0YYbT3t3DU8sdrfz5UTpiBNUu+jYv3vnzM3+k2s61W5z2nAhP\nR7Y3u8d/JeID7+Fnd37D8BQLfsPwFAt+w/AUC37D8BQLfsPwFAt+w/CUzKb6IhEUl7l7u3WS3nMA\nsH2NO5UWa+MpmQW/WkC1qy+/jGotDTzVh3Z3arE4wtNh4bC7ug0AEgUVVBtz2FSqjdrOq/oeffxh\np/39pe9Qn5NnzaLavLlXUS0R8PRJRNyVgp0BKTbEeUVlR2MD1TTJj9na7v59VlSUUJ9QQLVirIen\nl2+fdyPVphxXS7WmFvcxm/a4e0YCQFYuSQUrv4b92e+dX0QeFJFGEVnRx1YmIotEZH36f3edrmEY\nhywDedn/MIA5/Ww3A1isqpMBLE5/bxjGp4j9Br+qvg6g/2vyCwDs66DwCIALB3ldhmEMMQe64Vep\nqrvSX9cjNbHXiYjMFZE6Ealr2tN0gKczDGOwOejdflVVAHRChqrOV9VaVa0tr3Bv9hmGkXkONPgb\nRKQKANL/821JwzAOSQ401fccgCsA3JP+n5cs9SGZUHS3u0cy/fXV/6Z+by1e5LRf949XU5+/O/FU\nqn3xm1dS7ec3fpdqDTu2O+0h5eOuepU3dSw4bDLVsnJ5inAvz3AilnCvpQe8SWcii1cQ5ufzNGZP\nQFZpS4M7HdkTC2iQqvxelAhIsf1l0WKqbd7qrpg7fzZ/Dmxf+x7V/vtvb1PtvC99lWq7mnlT0O6o\nO5W9ZAlv4nrUUe7nTiLBz9OfgaT6ngDwJoApIrJdRK5EKujPEpH1AM5Mf28YxqeI/d75VZV9Iob3\nnTYM45DHPt5rGJ5iwW8YnmLBbxieYsFvGJ6S0aq+ZCKJrmZ3ldW4mvHc78TPOe1LlrxLfT5YwtM1\n8+/9MdUSwiu6jjzuOKf9yRfds9YAYEIhrx7r7qafjUJUuBbTMNVCee6UXmuMH6+HHw4tre6GoAAQ\nzuYpzpGj3M1Jc/N4CrO7y50GBoBQQOVe7fEnUO13Tz3jtK875yzqk1XMf2cbl/JPqd50231Uq6ji\nad0xNeOc9qlTj6Q+I0rcoRsOD/x+bnd+w/AUC37D8BQLfsPwFAt+w/AUC37D8BQLfsPwlIym+jSh\niHW60zmJBE/zxDRKjsfnkjXt3kW1Pzz1e6rl5PGUUvXho532jihv+tkb5VVW0Q5eqVaQy+fn5eUE\nNM5Mus+XVH6tArJo6OnlfokEr9ALh90p03jALLmQ8Nl04Sz+mBc+8RDVYnH3Opo6+e9lU2MH1TqS\nvDoyHubP4aXvr6faiCL3HMXNmz6kPhOPqHLak8lBbOBpGMZnEwt+w/AUC37D8BQLfsPwFAt+w/CU\nzBb2QNED945oS1sL9duxa5PT/tyTv6U+RfkBBTUBWYIJEw6nWltnq/tcBbnUJxHlDfcaG3ZQrSDK\nC2p6mngmozDhziDE2/k4tOyAwp7OLp6RyAoFOMa7nOZkQIYgtyigX2C3+3gAcNk3rqDas4tec9rn\n3fhD6lOQw7MOf3f8NKpNHj2RaiedzB/b7p3u3pBjx4yhPr9/8imnvXkvj6P+2J3fMDzFgt8wPMWC\n3zA8xYLfMDzFgt8wPMWC3zA8JaOpvngygaZ2d7oskXQX7wAAYu5004Xnz6Euj//hWarlFPHijNZO\nnirp2OseQZXo5OmweC9P9bW2uY8HAElSzAQAvU18NOL5s05x2osDUpivLuX9DvPy+Lix3l5eyJKb\nk/PJjxfnFUYS4U/VESWlVMuKuPsMdkX5uSJZfI1vLl3F/RI8HTmCt4bEqccf5RaSvO/iWWee77S/\n+K57PJmLgYzrelBEGkVkRR/bnSKyQ0SWpf+dN+AzGoZxSDCQl/0PA3DdYn+uqtPT/14Y3GUZhjHU\n7Df4VfV1APzjYYZhfCo5mA2/60Tkg/TbAvqmS0TmikidiNS1tg78o4eGYQwtBxr89wOYCGA6gF0A\nfsp+UFXnq2qtqtYWBwxDMAwjsxxQ8Ktqg6omVDUJYAGAEwd3WYZhDDUHlOoTkSpV3Vda9mUAK4J+\nfh/xRBK7O9ypr4q8EdSvN+5eZkT56Kd4L++Bhw5ehbdh1W6q1U491WnvVHdaCwACWtaht4FX561a\nVke1WEClYKzIfR1rRvJ02Ia3XqVafg5PY179D5dSLa/Y3e8wpjznFS7ka+zoaqNaj/JKwWLyuI8Y\nVU59dm4NqLbM469emxt4X8CugErSOOlP2NLFewnmFBW7hVBATrEf+w1+EXkCwBcAVIjIdgB3APiC\niEwHoAA2A7h6wGc0DOOQYL/Br6qXOcwPDMFaDMPIIPbxXsPwFAt+w/AUC37D8BQLfsPwlMw28NQE\nojF3+iI7n6fL2tvcPnsDqtsiubwi6q4f3Ua1urffoNrhU4502jXML2N3jKfl2qPNVMsKWL8E9c0k\nlXGNjQ3UJy+frz/azavfyit4U8qQuI9ZWekeMwUA3T187Fk8oIIwFOH3sKY97tRtazOvqOzt4anD\nrDBv7tkbkNetquBp6a5udwWnhAJ+L73uNSp/2nwMu/MbhqdY8BuGp1jwG4anWPAbhqdY8BuGp1jw\nG4anZDTVp8kkYj3utJ2Cp1C2bNvqtM/4HJ+bdtLsWVTrVl4tVXvqyVSLkqaPLT28mqs0zFNlvWFe\nMbelfjP3C5h3l+x2/z0fO76G+mzduoFqorzaMhzmjS5LKkY67UHz/fJyeLVlKKBajc1/BIBRoyqc\n9jNnn059Xnz+RarVjB1LtY5Wd3NaAGhp5bMXk1LttHfH+OPas9vdXCsW4NMfu/MbhqdY8BuGp1jw\nG4anWPAbhqdY8BuGp2R0t19EEA67C3jCWXy3/6JLL3HaVfjOZiKbH6+80t1fLuXIKyPiUfeO83XX\n30R9nnrqKart2sPHIRRVlFFt47qNVNMOd6+7TVvcGRMACAWMhWpt44VJpVW8GKuj3Z3JyM3mTzlN\n8iyGJnnRTCLOR5vt2O4u/lq48HfUJ6CGCE3NS6lWHtCdOh98/cmkOyPU0cmvfU3NOKc9O9s9nsyF\n3fkNw1Ms+A3DUyz4DcNTLPgNw1Ms+A3DUyz4DcNTBjKxpwbAowAqkZrQM19VfyEiZQB+B2A8UlN7\nLlZV3pQOABCCqLt4Iy+Pj9fKynP7JBGQ1sjKp9Kb76yl2vHTeLFQJMd9uY6cdgL1afvNs1RLRHmK\n6hc/uYdqK5cvodpDDzzo9lm1mvqMJkU4ABACL8RpbuaFLKXl7uu/p6WJ+kS7eA+/gGUgJLzoZ+zY\nUU57aZm74AcA9gSlYEfwkWL1W7dzjfShBIAJ1e7CsJJiMpILQHdnl9PO0oYuBnLnjwP4F1WdCuAk\nANeIyFQANwNYrKqTASxOf28YxqeE/Qa/qu5S1aXpr9sBrAZQDeACAI+kf+wRABcO1SINwxh8PtF7\nfhEZD+B4AG8DqOwzqbceqbcFhmF8Shhw8ItIIYCnAMxT1Y98hlRVFan9AJffXBGpE5G6jnY+Ztkw\njMwyoOAXkSykAn+hqj6dNjeISFVarwLg/BC1qs5X1VpVrS0ks+MNw8g8+w1+ERGkRnKvVtWf9ZGe\nA3BF+usrAPxx8JdnGMZQMZCqvlMBXA5guYgsS9tuAXAPgCdF5EoAWwBcvN8jqUCT7lNmZ/NxRhpy\nV4+VlvHKtx1NvD/eVy/6NtXq6+uplpvrTjm+9JfF1OfmW3nKbkLNGKp1tfF1jJt8NNWuv+UHTvvd\nd/6I+lSOdleIAcDWjeuolt3OU309UXdpXDLB05vRHnf6CgAQCqi2DBih1dDoTttt3+ke4wUA8YAq\nx1A9z2ZXj+Qp01gb7+EXCrnvwQW5vGpy+y738yOR4NWD/dlv8KvqGwBYInX2gM9kGMYhhX3CzzA8\nxYLfMDzFgt8wPMWC3zA8xYLfMDwlow08IQDJakCy+OinPXtJeiigqC8nv5xqyWRQk8MCqjTvdaev\nTjxpDvUZMYJ/sKlh54dUKwn4QFRRKV//yEp32u4n//vfqc+65cuotmLJm1RrD6hKLCx2p2EL83n6\nKiy8Iq2tg1fFSS7/nZ10knv8Wls7b465Zh0fX3beF79EtaVvvkG1rKDbLEnP7W7cGXA8d5kjr2/8\nOHbnNwxPseA3DE+x4DcMT7HgNwxPseA3DE+x4DcMT8loqi+pCXTE3A098vJ5A8/nX3jdab/hJt42\ncM3mLVRb9sFyqi345UNUu+22/+m0l5S5m0QCwD333kW1G6//J6plRXhlWWfADLc77rjdab/0K2dT\nn6OnHUW1f7vX/ZgB4Jp511NtytFTnfbtm/mcwUScV2JGAnJYPVF3A0wAWLPc3bh0dzNvLJNUfrJn\nnnqaaskob0DKn91Ab8z9uMPC783hsFsLamb6sZ8d8E8ahvGZwoLfMDzFgt8wPMWC3zA8xYLfMDwl\no7v9oVAI+fnuPnhxCeiblu0uBokr/9s1YfzhVCsq4v0C77v3X6m2fsNWp33sON6L79bv30i1vDy+\nM9vRwXejI9m8COqOu9y9+pJR3rNOonuoVr9jM9UeeOgBqn3tm9902qdMHE99du5wX18AKCzkv7Mo\n6QsJAFnqfl6V5PNxbm1dPJsi5HgAUFbCx2tpRwvVQJ7HInxGWTvJ+CQGeVyXYRifQSz4DcNTLPgN\nw1Ms+A3DUyz4DcNTLPgNw1P2m+oTkRoAjyI1glsBzFfVX4jInQCuArAvh3SLqr6wv+Mp6z3GmvsB\nSIbd6ZWObj7eqXI0T78l4wmqlYzgabSZM49z2ssruE9hIdf+9Uf/QbVzv3ge1ZqaeWouqe4+g3f/\n8A7qc+fN/0y1SUfz0WDROE973X2ve0zZnbfeRH2eWPgY1a666iqqaYyPqJpxrLto6dXX/kp9wgHj\nupLCz9Xawgt7qkt430UhRTq9QWPDskmqMqAYqD8DyfPHAfyLqi4VkSIAS0RkUVr7uar+ZMBnMwzj\nkGEgs/p2AdiV/rpdRFYDqB7qhRmGMbR8ovf8IjIewPEA3k6brhORD0TkQREpHeS1GYYxhAw4+EWk\nEMBTAOapahuA+wFMBDAdqVcGPyV+c0WkTkTqOtr5R1YNw8gsAwp+EclCKvAXqurTAKCqDaqaUNUk\ngAUATnT5qup8Va1V1drCgEEUhmFklv0Gv4gIgAcArFbVn/WxV/X5sS8DWDH4yzMMY6gYyG7/qQAu\nB7BcRPbNdboFwGUiMh2p9N9mAFfv70AiIWRF3CkKDUj1dXS5UyjlIyuoz4YNvFfc0UfxnnUFBfyS\njB3nPl8soJBq+/a9VPvapRdTraGpmWqFxfwVVG6+O6X0b3ffR33ylPfOiyfaqaYBM6iWrlzpXgdJ\nAQLA3T/4PtUWPvYo1S66+OtU++qXznfaRxbzCrxdjbwC8oNVa6nW2dVKtRAC0ofk+dPWxX8vRSWV\nTntQyrw/A9ntfwPuEWD7zekbhnHoYp/wMwxPseA3DE+x4DcMT7HgNwxPseA3DE/JaAPPcDiMYpJi\nScR5M8us7AKnPRR2N/YEgFGj+Ait/Fz+sMeN436Nu93VdF0BVWWJBH9c69bztFHVmIlUW/4+/0hF\nb8K9llOOP5L6SEcT1S6+4jKq3T9/AdXOPMddldi4ZR31uebaa6n20vN/otrCx3k14LTjZjjt372W\nZ6bbu3mKre69ZVTr6OigmsZ4xd/oCncKeeqx7rUDQFfSXR2bk+NukOvC7vyG4SkW/IbhKRb8huEp\nFvyG4SkW/IbhKRb8huEpGU31iQhys7KcWjzOS+OScbePBCy/uJTPdjt8Ek/ndXfzdYRC7orEpj07\nqE8i4W6oCQBnzJ5FtW07efpt2vRaqiVJajEEnoYKKgR7/LEnqMaasQLAh1s/dNrHjJ1AfYoi46g2\nNaASc/HLr1GtpMTdYGr12lUBPiVUO/us06m2adMGqu3auplq4w5zN5vND5gniF7ye/4EDTztzm8Y\nnmLBbxieYsFvGJ5iwW8YnmLBbxieYsFvGJ6S2aq+UAhFhe6qo+rR7oaEADB2rDsVMmlKDfXZQyrw\nAGDrDq61NLVQrXGPu0Hj/AUPUJ9HHubz+DZu5KmhcRMnUW3Per7+LVu2OO2TRhdSn+Is/jR4/vmX\nqTZr9myqja50/84i6KY+bS28cab28vmKM0/n64hG3anW6+d9l/pMmsQrKk877TSqVY4qp9rePfVU\nW7G0zmmfPuNk6tNGCg87O3n1YH/szm8YnmLBbxieYsFvGJ5iwW8YnmLBbxieIqp8jBAAiEgugNcB\n5CCVHfiDqt4hImUAfgdgPFLjui5WVT5jCsDRx07T3zztHvQzfmw19WvrcO8QxwKKgVr28jFZsa4u\nqhUX8jFOLR3uLdb8Al5EFBLe32/8eJ7hWLlmPdU643x3/vbb73Daf3rnTdRn28p3qXb44YdT7e33\nl1PtwUcedtrb2hqpz603zqNa5Ui+k97dFaNab9StJWI863DbrfxaTZ0yhWrFRXlUm3UC78eXF3YX\nrjU3R6lPIuLua/m/Hn8C2+obeOPIPgzkzh8FcIaqTkNqHPccETkJwM0AFqvqZACL098bhvEpYb/B\nryn21YNmpf8pgAsAPJK2PwLgwiFZoWEYQ8KA3vOLSDg9obcRwCJVfRtAparuSv9IPQD+GtYwjEOO\nAQW/qiZUdTqAMQBOFJFj+ukKuGcQi8hcEakTkbrmvbxBhWEYmeUT7faraguAVwDMAdAgIlUAkP7f\nuZOjqvNVtVZVa0vL+KaNYRiZZb/BLyIjRaQk/XUegLMArAHwHIAr0j92BYA/DtUiDcMYfAaS6jsO\nqQ29MFJ/LJ5U1btEpBzAkwDGAtiCVKqP59cAHHPcdH36+cVOrbiE9ytbvW6l037ElGOpz4rlfBRW\nYY47TQIAyQQvIJnxuSOc9tXrefoq0cvTUMuWvEO1KUfzlFJUeO88Vff6i8EfF1p5oVBnWzvVCkfy\nXoi95LYSjweMtIrzFGw8znshIuROlQFAjIzeeu3lv1CfM047lWpzr7qSapVlvHiqsog/5y658CtO\ne5RdRACxpHtU3b0PL8SWXfUDSvXtt6pPVT8AcLzD3gSAl1MZhnFIY5/wMwxPseA3DE+x4DcMT7Hg\nNwxPseA3DE/Zb6pvUE8mshuptCAAVADgOabMYev4KLaOj/JpW8c4VR05kANmNPg/cmKROlXlQ+ds\nHbYOW8eQrsNe9huGp1jwG4anDGfwzx/Gc/fF1vFRbB0f5TO7jmF7z28YxvBiL/sNw1Ms+A3DU4Yl\n+EVkjojtF/kBAAACk0lEQVSsFZENIjJsjT9FZLOILBeRZSLiHpg2NOd9UEQaRWRFH1uZiCwSkfXp\n/0uHaR13isiO9DVZJiLnZWAdNSLyioisEpGVIvLdtD2j1yRgHRm9JiKSKyLviMj76XX8MG0f3Ouh\nqhn9h1RfgI0AJgLIBvA+gKmZXkd6LZsBVAzDeU8DMAPAij62+wDcnP76ZgD3DtM67gRwfYavRxWA\nGemviwCsAzA109ckYB0ZvSYABEBh+ussAG8DOGmwr8dw3PlPBLBBVTepagzAb5HqBOwNqvo6gP6N\nTzLeDZmsI+Oo6i5VXZr+uh3AagDVyPA1CVhHRtEUQ94xeziCvxrAtj7fb8cwXOA0CuBlEVkiInOH\naQ37OJS6IV8nIh+k3xYM+duPvojIeKSaxwxrh+h+6wAyfE0y0THb9w2/mZrqSnwugGtEhA9fzyCa\nel03XDnY+5F6SzYdwC4AP83UiUWkEMBTAOapaltfLZPXxLGOjF8TPYiO2QNlOIJ/B4CaPt+PSdsy\njqruSP/fCOAZpN6SDBcD6oY81KhqQ/qJlwSwABm6JiKShVTALVTVp9PmjF8T1zqG65qkz/2JO2YP\nlOEI/ncBTBaRCSKSDeBSpDoBZxQRKRCRon1fAzgbwIpgryHlkOiGvO/JlebLyMA1EREB8ACA1ar6\nsz5SRq8JW0emr0nGOmZnagez327meUjtpG4EcOswrWEiUpmG9wGszOQ6ADyB1MvHXqT2PK4EUI7U\nzMP1AF4GUDZM63gMwHIAH6SfbFUZWMdMpF7CfgBgWfrfeZm+JgHryOg1AXAcgPfS51sB4Adp+6Be\nD/t4r2F4iu8bfobhLRb8huEpFvyG4SkW/IbhKRb8huEpFvyG4SkW/IbhKf8XJZtOCvne9l0AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1138e5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(indoor[0])\n",
    "plt.title('indoor')\n",
    "plt.show()\n",
    "plt.imshow(outdoor[0])\n",
    "plt.title('outdoor')\n",
    "plt.show()\n",
    "plt.imshow(preliminary_test_images[0])\n",
    "plt.title('test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Балансировка классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что размеры классов очень несбалансированы. Линейные модели, в частности логистическая регрессия, плохо работают на таких данных. Нужно сбалансировать размеры классов. Для этого сделаем клоны объектов меньшего класса (outdoor). Но для достижения более хороших результатов сделаем не просто клоны, а зеркальные клоны, то есть зеркально перевернем картинки (лево-право). Почему так можно? Заметим, что в данном случае зеркальное отображение не портит ответ, так как картинка и зеркально перевернутая картинка одинаково относятся либо к улице, либо к помещению. При этом такое клонирование даст нам новые данные, на которых мы сможем обучиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем зеркально отображенные картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdoor_mapping = []\n",
    "for image in outdoor:\n",
    "    outdoor_mapping.append(image[:, ::-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В классе outdoor стало: 4406 картинок \n"
     ]
    }
   ],
   "source": [
    "outdoor = np.concatenate((outdoor, outdoor_mapping))\n",
    "print('В классе outdoor стало: {} картинок '.format(outdoor.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полной балансировки классов осталось добавить 296 картинок из класса outdoor. Добавим рандомные 296 картинок из уже имеющихся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В классе outdoor стало: 4702 картинок \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random_indeces = np.random.choice(outdoor.shape[0], 296)\n",
    "outdoor = np.concatenate((outdoor, outdoor[random_indeces]))\n",
    "print('В классе outdoor стало: {} картинок '.format(outdoor.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем выборку и ответы к ней. Для удобства ответ для каждой картинки представим в виде пары чисел, где первое число отвечает за то принадлежит ли объект классу indoor, а второе за принадлежность классу outdoor. То есть если объект принадлежит indoor, то ответ будет (1, 0), если outdoor, то (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборки:  (9404, 32, 32, 3)\n",
      "Размер ответов:  (9404, 2)\n"
     ]
    }
   ],
   "source": [
    "preliminary_data = np.concatenate((indoor, outdoor))\n",
    "temp = np.append(np.ones(indoor.shape[0]) , np.zeros(outdoor.shape[0])).reshape((1, preliminary_data.shape[0]))\n",
    "labels = np.concatenate((temp, 1 - temp)).T\n",
    "print('Размер выборки: ', preliminary_data.shape)\n",
    "print('Размер ответов: ' , labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решафл данных\n",
    "Наши данные отсортированны по классам. Сначала идет класс indoor, потом outdoor. Нужно их зарешафлить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "indeces_shuffle = np.arange(preliminary_data.shape[0])\n",
    "np.random.shuffle(indeces_shuffle)\n",
    "preliminary_data = preliminary_data[indeces_shuffle].reshape(preliminary_data.shape)\n",
    "labels = labels[indeces_shuffle].reshape(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление фичей\n",
    "1) Заметим, что пиксели кроме нужной информации несут еще и мусорную информацию. Пример для понимания: если у нас есть трава и на ней лежит что-то маленькое красного цвета, то этот красный пиксель нам не даст никакой информации о том, что это картинка улицы. Даже наоборот, этот пиксель может испортить наше предсказание.<br>\n",
    "Поэтому идея : не рассматривать все цвета, имеющиеся на картинке, а рассматривать кол-во цветов на картинке, попавшие в определенные промежутки цветов. То есть разделим все цвета на $k$ равных промежутков и посмотрим как наши исходные цвета распределились по ним. Для этого построим гистограмму распределения цветов. <br>\n",
    "Сделаем то же самое  только не для всей картинки, а для подкартинок - прямоугольников размера $p*q$. Я разбивала картинку на 16 квадратов размера $8*8$ и на 64 квадрата размера $4*4$.<br> <br>\n",
    "2) Для всей картинки посмотрим на среднее значение и на отклонение по каждому из каналов. <br> \n",
    "Для каждой подкартинки (квадрата размера $8*8$ и $4*4$) также посмотрим на среднее значение и на отклонение по каждому из каналов. <br> <br>\n",
    "3) Для всей картинки по каждому из каналов (R G B) посмотрим на примерное максимальное и минимальное значение интенсивности этого канала. Здесь примерный означает среднее значение 10ти пикселей с максимальным значением интенсивности и 10ти с минимальным значением.  (Это сделает модель более устойчивой к выбросам)<br> То же самое сделаем для квадратов размера $8*8$ и $4*4$.<br> <br>\n",
    "4) Построим гистограмму аналогичную пункту 1), только для каждого из каналов. Также сделаем для подкартинок размерами $4*4$ и $8*8$ <br> <br>\n",
    "5) hog - гистограмма градиентов для изображения (база (псевдокод) взята из Стэнфордского курса CS231) <br>\n",
    "Сначала нам нужно для каждого пикселя вычислить вектор градиента, что является просто мерой изменения значений пикселей вдоль направления x и y-направления вокруг каждого пикселя.  <br> \n",
    "Как считать вектор градиента? Для начала нужно перевести картинку в черно-белый. После для каждого пикселя мы рассматриваем пиксели слева и справа и сверху и снизу. Пусть для текущего пикселя значения пикселя справа - a, слева - b, снизу - c, сверху -  d. Вектор градиента для этого пикселя равен $(a-b, c-d)$. Тогда величина градиента равна $\\sqrt{(a-b)^2 + (c-d)^2}$, а угол равен $arctg(\\frac{c-d}{a-b})$ <br>\n",
    "\n",
    "Внутри выбранной подкартинки (в нашем случае $8*8$ и $4*4$) мы вычисляем вектор градиента на каждом пикселе. <br>\n",
    "После мы берем все эти векторы градиента и помещаем их в гистограмму с 9тью корзинками. Каждая корзинка - угол в 20 градусов (0-20, 20-40,..., 160-180).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные функции, которые возвращают для определенной фичи матрицу, где каждая строка является массивом этой фичи для определенного объекта из data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hist_hsv_full(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        to_hsv = matplotlib.colors.rgb_to_hsv(data[i] / 255)\n",
    "        hist, bin_edges = np.histogram(to_hsv[:,:,0], range=(0, 1), bins=20, density=True)\n",
    "        feature.append(list(hist))\n",
    "    return np.array(feature)\n",
    "    \n",
    "def hist_hsv_8_8(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        feature_i = np.array([])\n",
    "        for a in range(4):\n",
    "            for b in range(4):\n",
    "                to_hsv = matplotlib.colors.rgb_to_hsv(data[i][8*a : 8*(a+1), 8*b : 8*(b+1), :] / 255)\n",
    "                hist, bin_edges = np.histogram(to_hsv[:,:,0], range=(0, 1), bins=20, density=True)\n",
    "                feature_i = np.concatenate((feature_i, hist))\n",
    "        feature.append(list(feature_i))\n",
    "    return np.array(feature)\n",
    "\n",
    "\n",
    "def hist_hsv_4_4(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        feature_i = np.array([])\n",
    "        for a in range(8):\n",
    "            for b in range(8):\n",
    "                to_hsv = matplotlib.colors.rgb_to_hsv(data[i][4*a : 4*(a+1), 4*b : 4*(b+1), :] / 255)\n",
    "                hist, bin_edges = np.histogram(to_hsv[:,:,0], range=(0, 1), bins=20, density=True)\n",
    "                feature_i = np.concatenate((feature_i, hist))\n",
    "        feature.append(list(feature_i))\n",
    "    return np.array(feature)\n",
    "\n",
    "def mean_std_channel_full(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        mean_red = data[i][:,:,0].mean() / 255\n",
    "        mean_green = data[i][:,:,1].mean()  / 255\n",
    "        mean_blue = data[i][:,:,2].mean()  / 255\n",
    "        std_red = data[i][:,:,0].std() / 255\n",
    "        std_green = data[i][:,:,1].std()  / 255\n",
    "        std_blue = data[i][:,:,2].std()  / 255\n",
    "        feature.append([mean_red, mean_green, mean_blue, std_red, std_green, std_blue,\n",
    "                       np.sqrt(std_red), np.sqrt(std_green), np.sqrt(std_blue)])\n",
    "    return np.array(feature)\n",
    "\n",
    "def mean_std_channel_8_8(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        feature_i = np.array([])\n",
    "        for a in range(4):\n",
    "            for b in range(4):\n",
    "                mean_red = data[i][8*a : 8*(a+1), 8*b : 8*(b+1), 0].mean()  / 255\n",
    "                mean_green = data[i][8*a : 8*(a+1), 8*b : 8*(b+1) ,1].mean()  / 255\n",
    "                mean_blue = data[i][8*a : 8*(a+1), 8*b : 8*(b+1) ,2].mean()  / 255\n",
    "                std_red = data[i][8*a : 8*(a+1), 8*b : 8*(b+1), 0].std()  / 255\n",
    "                std_green = data[i][8*a : 8*(a+1), 8*b : 8*(b+1) ,1].std()  / 255\n",
    "                std_blue = data[i][8*a : 8*(a+1), 8*b : 8*(b+1) ,2].std()  / 255\n",
    "                feature_i = np.concatenate((feature_i,[mean_red, mean_green, mean_blue, std_red, std_green, std_blue,\n",
    "                                                      np.sqrt(std_red), np.sqrt(std_green), np.sqrt(std_blue)]))\n",
    "        feature.append(list(feature_i))\n",
    "    return np.array(feature)\n",
    "\n",
    "\n",
    "def mean_std_channel_4_4(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        feature_i = np.array([])\n",
    "        for a in range(8):\n",
    "            for b in range(8):\n",
    "                mean_red = data[i][4*a : 4*(a+1), 4*b : 4*(b+1), 0].mean()  / 255\n",
    "                mean_green = data[i][4*a : 4*(a+1), 4*b : 4*(b+1) ,1].mean()  / 255\n",
    "                mean_blue = data[i][4*a : 4*(a+1), 4*b : 4*(b+1) ,2].mean()  / 255\n",
    "                std_red = data[i][4*a : 4*(a+1), 4*b : 4*(b+1), 0].std()  / 255\n",
    "                std_green = data[i][4*a : 4*(a+1), 4*b : 4*(b+1) ,1].std()  / 255\n",
    "                std_blue = data[i][4*a : 4*(a+1), 4*b : 4*(b+1) ,2].std()  / 255\n",
    "                feature_i = np.concatenate((feature_i,[mean_red, mean_green, mean_blue, std_red, std_green, std_blue,\n",
    "                                                      np.sqrt(std_red), np.sqrt(std_green), np.sqrt(std_blue)]))\n",
    "        feature.append(list(feature_i))\n",
    "    return np.array(feature)\n",
    "\n",
    "def min_max_channel_full(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        sorted_red = np.sort(data[i][:,:,0].ravel())\n",
    "        sorted_green = np.sort(data[i][:,:,1].ravel())\n",
    "        sorted_blue = np.sort(data[i][:,:,2].ravel())\n",
    "        max_red = sorted_red[-10:].mean()  / 255\n",
    "        min_red = sorted_red[:10].mean()  / 255\n",
    "        max_green = sorted_green[-10:].mean()  / 255\n",
    "        min_green = sorted_green[:10].mean()  / 255\n",
    "        max_blue = sorted_blue[-10:].mean()  / 255\n",
    "        min_blue = sorted_blue[:10].mean()  / 255\n",
    "        feature.append([max_red,min_red, max_green, min_green, max_blue, min_blue])\n",
    "    return np.array(feature)\n",
    "\n",
    "def min_max_channel_8_8(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        feature_i = np.array([])\n",
    "        for a in range(4):\n",
    "            for b in range(4):    \n",
    "                sorted_red = np.sort(data[i][8*a : 8*(a+1), 8*b : 8*(b+1) ,0].ravel())\n",
    "                sorted_green = np.sort(data[i][8*a : 8*(a+1), 8*b : 8*(b+1) ,1].ravel())\n",
    "                sorted_blue = np.sort(data[i][8*a : 8*(a+1), 8*b : 8*(b+1) ,2].ravel())\n",
    "                max_red = sorted_red[-8:].mean()  / 255\n",
    "                min_red = sorted_red[:8].mean()  / 255\n",
    "                max_green = sorted_green[-8:].mean()  / 255\n",
    "                min_green = sorted_green[:8].mean()  / 255\n",
    "                max_blue = sorted_blue[-8:].mean()  / 255\n",
    "                min_blue = sorted_blue[:8].mean()  / 255\n",
    "                feature_i = np.concatenate((feature_i, [max_red,min_red, max_green, min_green, max_blue, min_blue]))\n",
    "        feature.append(list(feature_i))\n",
    "    return np.array(feature)\n",
    "                \n",
    "def min_max_channel_4_4(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        feature_i = np.array([])\n",
    "        for a in range(8):\n",
    "            for b in range(8):    \n",
    "                sorted_red = np.sort(data[i][4*a : 4*(a+1), 4*b : 4*(b+1) ,0].ravel())\n",
    "                sorted_green = np.sort(data[i][4*a : 4*(a+1), 4*b : 4*(b+1) ,1].ravel())\n",
    "                sorted_blue = np.sort(data[i][4*a : 4*(a+1), 4*b : 4*(b+1) ,2].ravel())\n",
    "                max_red = sorted_red[-4:].mean()  / 255\n",
    "                min_red = sorted_red[:4].mean()  / 255\n",
    "                max_green = sorted_green[-4:].mean()  / 255\n",
    "                min_green = sorted_green[:4].mean()  / 255\n",
    "                max_blue = sorted_blue[-4:].mean()  / 255\n",
    "                min_blue = sorted_blue[:4].mean()  / 255\n",
    "                feature_i = np.concatenate((feature_i, [max_red,min_red, max_green, min_green, max_blue, min_blue]))\n",
    "        feature.append(list(feature_i))  \n",
    "    return np.array(feature)\n",
    "                \n",
    "                \n",
    "def hist_channel_full(data):\n",
    "    feature = []              \n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        hist_red, bin_edges = np.histogram(data[i][:, :,0] / 255, range=(0, 1), bins=10, density=True)\n",
    "        hist_green, bin_edges = np.histogram(data[i][:, :,1] / 255, range=(0, 1), bins=10, density=True)\n",
    "        hist_blue, bin_edges = np.histogram(data[i][:, :,2] / 255, range=(0, 1), bins=10, density=True)\n",
    "        feature.append(list(hist_red) + list(hist_green) + list(hist_blue))\n",
    "    return np.array(feature)\n",
    "                \n",
    "                \n",
    "def hist_channel_8_8(data):\n",
    "    feature = []                \n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        feature_i = np.array([])\n",
    "        for a in range(4):\n",
    "            for b in range(4):\n",
    "                hist_red, bin_edges = np.histogram(data[i][8*a : 8*(a+1), 8*b : 8*(b+1),0] / 255, range=(0, 1), bins=10, density=True)\n",
    "                hist_green, bin_edges = np.histogram(data[i][8*a : 8*(a+1), 8*b : 8*(b+1),1] / 255, range=(0, 1), bins=10, density=True)\n",
    "                hist_blue, bin_edges = np.histogram(data[i][8*a : 8*(a+1), 8*b : 8*(b+1),2] / 255, range=(0, 1), bins=10, density=True)\n",
    "                feature_i = np.concatenate((feature_i, list(hist_red) + list(hist_green) + list(hist_blue)))\n",
    "        feature.append(list(feature_i))\n",
    "    return np.array(feature)\n",
    "                \n",
    "                \n",
    "def hist_channel_4_4(data):\n",
    "    feature = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        feature_i = np.array([])\n",
    "        for a in range(8):\n",
    "            for b in range(8):\n",
    "                hist_red, bin_edges = np.histogram(data[i][4*a : 4*(a+1), 4*b : 4*(b+1),0] / 255, range=(0, 1), bins=10, density=True)\n",
    "                hist_green, bin_edges = np.histogram(data[i][4*a : 4*(a+1), 4*b : 4*(b+1),1] / 255, range=(0, 1), bins=10, density=True)\n",
    "                hist_blue, bin_edges = np.histogram(data[i][4*a : 4*(a+1), 4*b : 4*(b+1),2] / 255, range=(0, 1), bins=10, density=True)\n",
    "                feature_i = np.concatenate((feature_i, list(hist_red) + list(hist_green) + list(hist_blue)))\n",
    "        feature.append(list(feature_i))\n",
    "    return np.array(feature)\n",
    "                \n",
    "            \n",
    "#гистограмма градиентов\n",
    "#разделяем на квадраты 8*8 клеток\n",
    "def hog_8_8(data):\n",
    "    feature = []  \n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        #конвертируем в черно-белый\n",
    "        gray_image = np.dot(data[i][...,:3], [0.299, 0.587, 0.144])\n",
    "        #кол-во корзинок\n",
    "        orientations = 9\n",
    "\n",
    "        #считаем градиенты по направлениям\n",
    "        \n",
    "        gx = np.zeros(gray_image.shape)\n",
    "        gy = np.zeros(gray_image.shape)\n",
    "        \n",
    "        #по первому направлению \n",
    "        #считаем попарные разницы между соседними пикселями по горизонтальному направлению\n",
    "        gx[:, :-1] = np.diff(gray_image, n=1, axis=1)\n",
    "        #по второму направлению\n",
    "        gy[:-1, :] = np.diff(gray_image, n=1, axis=0)\n",
    "        \n",
    "        # находим величину градиента и угол\n",
    "        grad_value = np.sqrt(gx ** 2 + gy ** 2)\n",
    "        grad_angle = np.arctan2(gy, (gx + 1e-15)) * (180 / np.pi) + 90\n",
    "        \n",
    "        orientation_hist = np.zeros((4, 4, orientations))\n",
    "        for j in range(orientations):\n",
    "            #находим градиенты, которые лежат в определенном углу в 20 градусов\n",
    "            definite_angle = np.where(grad_angle < 180 / orientations * (j + 1), grad_angle, 0)\n",
    "            definite_angle = np.where(grad_andle >= 180 / orientations * j, definite_angle, 0)\n",
    "            #получаем массив из True и False в зависимости от принадлежности угла определенном углу в 20 градусов\n",
    "            temp = definite_angle > 0\n",
    "            #рассматриваем величины градиентов, попавших в этот угол\n",
    "            definite_value = np.where(temp, grad_value, 0)\n",
    "            orientation_hist[:,:,j] = uniform_filter(definite_value, size=(8, 8))[4::8, 4::8].T\n",
    "        feature.append(list(orientation_hist.ravel()))\n",
    "    return np.array(feature)\n",
    "\n",
    "def hog_4_4(data):\n",
    "    feature = []  \n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        #конвертируем в черно-белый\n",
    "        gray_image = np.dot(data[i][...,:3], [0.299, 0.587, 0.144])\n",
    "        #кол-во корзинок\n",
    "        orientations = 9\n",
    "\n",
    "        #считаем градиенты по направлениям\n",
    "        \n",
    "        gx = np.zeros(gray_image.shape)\n",
    "        gy = np.zeros(gray_image.shape)\n",
    "        \n",
    "        #по первому направлению \n",
    "        #считаем попарные разницы между соседними пикселями по горизонтальному направлению\n",
    "        gx[:, :-1] = np.diff(gray_image, n=1, axis=1)\n",
    "        #по второму направлению\n",
    "        gy[:-1, :] = np.diff(gray_image, n=1, axis=0)\n",
    "        \n",
    "        # находим величину градиента и угол\n",
    "        grad_value = np.sqrt(gx ** 2 + gy ** 2)\n",
    "        grad_angle = np.arctan2(gy, (gx + 1e-15)) * (180 / np.pi) + 90\n",
    "        \n",
    "        orientation_hist = np.zeros((8, 8, orientations))\n",
    "        for j in range(orientations):\n",
    "            #находим градиенты, которые лежат в определенном углу в 20 градусов\n",
    "            definite_angle = np.where(grad_angle < 180 / orientations * (j + 1), grad_angle, 0)\n",
    "            definite_angle = np.where(grad_andle >= 180 / orientations * j, definite_angle, 0)\n",
    "            #получаем массив из True и False в зависимости от принадлежности угла определенном углу в 20 градусов\n",
    "            temp = definite_angle > 0\n",
    "            #рассматриваем величины градиентов, попавших в этот угол\n",
    "            definite_value = np.where(temp, grad_value, 0)\n",
    "            orientation_hist[:,:,j] = uniform_filter(definite_value, size=(4, 4))[2::4, 2::4].T\n",
    "        feature.append(list(orientation_hist.ravel()))\n",
    "    return np.array(feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, возвращающая 2 словаря: словарь из фичей для наших данных и такой же словарь для тестовых данных. Ключи - названия фичей, значения - матрицы , составленные из фичей, где строка матрицы отвечает одному объекту из "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_features(data, test_data):\n",
    "    features_train = dict()\n",
    "    features_test = dict()\n",
    "    \n",
    "    #1\n",
    "    features_train['hist_hsv_full'] = hist_hsv_full(data)\n",
    "    features_test['hist_hsv_full'] = hist_hsv_full(test_data)\n",
    "    \n",
    "    features_train['hist_hsv_8_8'] = hist_hsv_8_8(data)\n",
    "    features_test['hist_hsv_8_8'] = hist_hsv_8_8(test_data)\n",
    "           \n",
    "    features_train['hist_hsv_4_4'] = hist_hsv_4_4(data)\n",
    "    features_test['hist_hsv_4_4'] = hist_hsv_4_4(test_data)\n",
    "    \n",
    "    #2\n",
    "    features_train['mean_std_channel_full'] = mean_std_channel_full(data)\n",
    "    features_test['mean_std_channel_full'] = mean_std_channel_full(test_data)\n",
    "    \n",
    "    features_train['mean_std_channel_8_8'] = mean_std_channel_8_8(data)\n",
    "    features_test['mean_std_channel_8_8'] = mean_std_channel_8_8(test_data)\n",
    "        \n",
    "    features_train['mean_std_channel_4_4'] = mean_std_channel_4_4(data)\n",
    "    features_test['mean_std_channel_4_4'] = mean_std_channel_4_4(test_data)\n",
    "    \n",
    "    #3\n",
    "    features_train['min_max_channel_full'] = min_max_channel_full(data)\n",
    "    features_test['min_max_channel_full'] = min_max_channel_full(test_data)\n",
    "\n",
    "    features_train['min_max_channel_8_8'] = min_max_channel_8_8(data)\n",
    "    features_test['min_max_channel_8_8'] = min_max_channel_8_8(test_data)\n",
    "\n",
    "    features_train['min_max_channel_4_4'] = min_max_channel_4_4(data)\n",
    "    features_test['min_max_channel_4_4'] = min_max_channel_4_4(test_data)\n",
    "    \n",
    "    #4 распределение по отдельным каналам\n",
    "    features_train['hist_channel_full'] = hist_channel_full(data)\n",
    "    features_test['hist_channel_full'] = hist_channel_full(test_data)\n",
    "\n",
    "    features_train['hist_channel_8_8'] = hist_channel_8_8(data)\n",
    "    features_test['hist_channel_8_8'] = hist_channel_8_8(test_data)\n",
    "\n",
    "    features_train['hist_channel_4_4'] = hist_channel_4_4(data)\n",
    "    features_test['hist_channel_4_4'] = hist_channel_4_4(test_data)\n",
    "    \n",
    "    #5\n",
    "    features_train['hog_8_8'] = hog_8_8(data)\n",
    "    features_test['hog_8_8'] = hog_8_8(test_data)\n",
    "    \n",
    "    features_train['hog_4_4'] = hog_4_4(data)\n",
    "    features_test['hog_4_4'] = hog_4_4(test_data)\n",
    "\n",
    "    return features_train, features_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**работает минут 15** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffcd2e4e91d4073999e06d446fa9099"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8d7ed5fda84d96b22c67245d9ea707"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ec5391666c4dfdbe0a7d04679650b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43dcaa0552745ba80fa96ba462d89a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfedd5097024067994c57f2d6fdb212"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b17e9f39deb46a985e6487a32ab4c5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76764e638594a2c9e673f242d82c8b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86499503c7e64bcfaf5ef2920eb8c100"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad340b2a0a7e493e874a4077043c53ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3efd444e934699a26ae42af5a12d26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0024b51de97e44e284924bf3e7a13521"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1463a54c44f54983a16a97b811888c3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354341593a004acd9a40fc0f0cec526f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b3069d3beb4437bee4c9e03b6f063d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6b80a6604144adb1d21551404ffbb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83156e0939d44eb9504a4b2e928f15b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca559f6b03ea4b9cb2e8ce2fab2052fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18de46754e0b47a7b7008e5585c5bd39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ce1c0fd8fb43bda2a3f9eb94545e9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506b3e157f0643fc8f50fa98969abeaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3edfb8a3584401d884b0033a0d19e3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf96a6683e54aa28928040ad9164363"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf68fbd02464d669fb9c92aa2a485f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8047c4e488474d0e8aab41a6f41e9fb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cf923198914634968af5e79c6428af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ccf8e917c3446bb8f5bbf3bbd558c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94641a833b7244bf9e510da0bf58b56c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587b11372845498280616e44d6dd406a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_save_features, _save_features_test = dict_features(preliminary_data, preliminary_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_data, dict_test_images = _save_features.copy(), _save_features_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория для выполнения.  <br>\n",
    "Пусть W - матрица весов размера D * C, где D - размер вектора, представляющего картинку, C - кол-во классов, то есть C = 2 <br>\n",
    "Матрица X - матрица размера N * D, где где N - кол-во картинок. <br>\n",
    "y - вектор ответов. <br><br>\n",
    "В данном случае минимизируемая функция это кросс-энтропия (log-loss). В нашем случае для $x_i$ она равна $$L_{x_i} = -\\sum_{j=1}^{j=2} y^{j}_{true, i} * log(y^{j}_{pred, i}) $$ , <br>\n",
    "где $y_{true, i}$ - вектор истинных ответов для i-ой картинки ($x_i$), то есть вектор длины 2 с одной 1 и остальными 0. <br>\n",
    "$y_{pred, i}$ - вектор предсказанных вероятностей для i-ой картинки ($x_i$), то есть вектор длины 2 состоящий из вероятностей принадлежности i-ой картинки к классам. <br>\n",
    "Заметим, что элементы вектора $y_{true, i}$ - нули во всех местах, кроме истинного класса, а на месте истинного класса стоит 1. Пусть номер истинного класса - $k$ <br>\n",
    "Тогда $$L_{x_i} = -\\sum_{j=1}^{j=2} y^{j}_{true, i} * log(y^{j}_{pred, i}) = - y^{k}_{true, i} * log(y^{k}_{pred, i}) = -log(y^{k}_{pred, i})$$ <br> \n",
    "Таким образом, если картинка $x_i$ принадлежит классу $k$, то $L_{x_i} = -log(y^{k}_{pred, i})$ <br>\n",
    "При этом, чтобы получить именно вероятности, а не большие числа, нам предлагают использовать $softmax(x) = \\frac{e^x}{\\sum(e^x)}$ <br>\n",
    "Поэтому вместо $y^{j}_{pred, i}$ в кросс-энтропию мы подставляем $softmax(y^{j}_{pred, i})$ (для приведения к вероятностям) <br>\n",
    "Тогда получим : $$L_{x_i} = -log(softmax(y^{k}_{pred, i})) = -log(\\frac{e^{y^{k}_{pred, i}}}{\\sum_{j=1}^{2} e^{y^{j}_{pred, i}}}) = - y^{k}_{pred, i} + log(\\sum_{j=1}^{2} e^{y^{j}_{pred, i}})$$ <br>\n",
    "<br>\n",
    "Итоговая кросс-энтропия - среднее значение для всех объектов: $L = \\frac{1}{N} \\sum_{i=1}^{N} L_{x_i}$ <br>\n",
    "Минимизировать кросс-энтропию будем градиентным спуском. Для этого нам понадобится уметь находить градиент функции $L$ <br>\n",
    "Сначала поймем, что $y^{j}_{pred, i} = <w_j x_i>$ <br>\n",
    "Тогда $$L_{x_i} = -<w_k x_i> + log(\\sum_{j=1}^{2} e^{<w_j x_i>})$$ <br>\n",
    "(напоминание $k$ - номер истинного класса картинки $x_i$) <br>\n",
    "Продифференцируем: \n",
    "$$\\frac{d L_{x_i}}{d w_k} = -x_i + \\frac{e^{<w_k x_i>}}{\\sum_{j=1}^{2} e^{<w_j x_i>}} x_i = (-1 + \\frac{e^{<w_k x_i>}}{\\sum_{j=1}^{2} e^{<w_j x_i>}}) x_i = (-1 + \\frac{e^{y^{k}_{pred, i}}}{\\sum_{j=1}^{2} e^{y^{j}_{pred, i}}}) x_i = (-1 + softmax(y^{k}_{pred, i})) \\; x_i$$\n",
    "\n",
    "$$\\frac{d L_{x_i}}{d w_s} = \\frac{e^{<w_s x_i>}}{\\sum_{j=1}^{2} e^{<w_j x_i>}} x_i = \\frac{e^{y^{s}_{pred, i}}}{\\sum_{j=1}^{2} e^{y^{j}_{pred, i}}} x_i = softmax(y^{s}_{pred, i})\\; x_i\\;\\;\\;\\; \\;\\;\\; s \\ne k$$ <br>\n",
    "\n",
    "Заметим, что вычитаем 1 только в тех местах, где в матрице $y_{true}$ стоит 1. <br>\n",
    "В силу того, что в матрице $y_{true}$ в остальных местах стоят нули, получим  $$\\frac{d L}{d W} = \\frac{1}{N}(softmax(y_{pred}) - y_{true}) X$$ <br>\n",
    "<br>\n",
    "Можно, конечно, было считать градиент численно по формуле $\\frac{f(x + dx) - f(x)}{dx}$ взяв маленький $dx$, но это даст бОльшую погрешность, чем аналитический способ. \n",
    "<br> <br>\n",
    "Также заметим, что все вышеописанное было только в терминах $X$  и $W$. Для того, чтобы не считать градиент по $b$ сделаем следующее: <br> Добавим к матрице $W$ в конец строчку из b_i (сначала это нули, потом модель подберет нужные числа), то есть теперь матрица имеет размер (D+1) * C, а к матрице $X$ добавим в конец столбец из единиц, то есть теперь матрица имеет размер N * (D+1). <br>\n",
    "Тогда при умножении $X W$ мы как раз получим аналог вектора $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация <br>\n",
    "Теперь для того, чтобы избежать переобучения, будем штрафовать модель за большие веса (большие веса один из признаков переобучения). <br> \n",
    "###### L2-регулизация\n",
    "Для этого к минимизируемой функции $L$ добавим $L_2$-регуляризацию. То есть теперь минимизируем функцию: $$L = \\frac{1}{N} \\sum_{i=1}^{N} L_{x_i} + \\sum_{j=1}^{C} \\sum_{k=1}^{D+1}{w_{j, k}}^2 = \\frac{1}{N} \\sum_{i=1}^{N} L_{x_i} + \\lambda ||W||^2$$ <br>\n",
    "(Напоминание, $C$ - кол-во классов, $D+1$ - кол-во признаков, включая единичный признак для имитирования вектора свободных коэффициентов), $\\lambda$ - коэффициент регуляризации <br> <br>\n",
    "\n",
    "Теперь нужно научиться находить градиент новой функции $L$. <br>\n",
    "$$\\frac{d ||W||^2}{dw_{i, j}} = \\frac{d(\\sum_{j=1}^{C} \\sum_{k=1}^{D+1}{w_{j, k}}^2)}{d w_{i, j}} = 2 w_{i, j}$$ <br>\n",
    "$$\\Rightarrow \\frac{d ||W||^2}{dW} = 2  W$$ <br>\n",
    "$$\\Rightarrow \\frac{dL}{dW} = \\frac{1}{N}(softmax(y_{pred}) - y_{true}) X + 2\\lambda W $$\n",
    "\n",
    "###### L1-регулизация\n",
    "Минимизируем функцию: $$L = \\frac{1}{N} \\sum_{i=1}^{N} L_{x_i} + \\sum_{j=1}^{C} \\sum_{k=1}^{D+1}{|w_{j, k}|}$$ <br>\n",
    "Ищем градиент\n",
    "$$\\frac{d(\\sum_{j=1}^{C} \\sum_{k=1}^{D+1}{|w_{j, k}}|)}{d w_{i, j}} = sign(w_{i, j})$$ <br>\n",
    "$$\\Rightarrow \\frac{d (\\sum_{j=1}^{C} \\sum_{k=1}^{D+1}{|w_{j, k}}|)}{dW} = sign(W)$$ <br>\n",
    "$$\\Rightarrow \\frac{dL}{dW} = \\frac{1}{N}(softmax(y_{pred}) - y_{true}) X + \\lambda sign(W) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции softmax, кросс-энтропия и поиск градиента (градиент ищем аналитически в зависимости от типа регуляризации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(y_pred):\n",
    "    temp = np.exp(y_pred)\n",
    "    return (temp / np.sum(temp, axis=1).reshape((temp.shape[0], 1)))\n",
    "\n",
    "def log_loss(W, X, y, penalty='l1', lambd=0.01):\n",
    "    y_pred = X.dot(W)\n",
    "    L = (- y_pred[y==1] + np.log(np.sum(np.e ** (y_pred), axis=1))).mean()\n",
    "    if penalty == 'l2':\n",
    "        return L + lambd * np.linalg.norm(W)\n",
    "    elif penalty == 'l1':\n",
    "        return L + lambd * np.sum(np.abs(W))\n",
    "\n",
    "def gradient(W, X, y, penalty='l1', lambd=0.01):\n",
    "    grad = (X.T).dot(softmax(X.dot(W)) - y) / (X.shape[0])\n",
    "    if penalty=='l2':\n",
    "        return grad + lambd * 2*W\n",
    "    elif penalty =='l1':\n",
    "        return grad + lambd * np.sign(W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск. Шаг будем выбирать по методу Adam. <br>\n",
    "Также на каждой итерации градиент будем вычислять не по всей выборке, а на ее случайной части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientDescentAdam(W, X_train, y_train, n_iter, X_test=None, y_test=None, eta=0.0001, beta1=0.9, beta2=0.999, \\\n",
    "                        eps=1e-8, penalty='l1', lambd = 1e-4, batch_size=400, trade=False):\n",
    "    \n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    m = np.zeros((W.shape))\n",
    "    v = np.zeros((W.shape))\n",
    "    for i in (range(n_iter)):\n",
    "        \n",
    "        np.random.seed(i+3)\n",
    "        indeces = np.random.choice(X_train.shape[0], batch_size)\n",
    "    \n",
    "        X_batch = X_train[indeces]\n",
    "        y_batch = y_train[indeces]\n",
    "        \n",
    "        grad = gradient(W, X_batch, y_batch, penalty=penalty, lambd=lambd)\n",
    "        \n",
    "        m = beta1*m + (1-beta1) * grad\n",
    "        v = beta2*v + (1-beta2) * (grad**2)\n",
    "        W = W - eta * m / (np.sqrt(v) + eps)\n",
    "        \n",
    "        if(trade):\n",
    "            losses_train.append(log_loss(W, X_train, y_train, penalty=penalty, lambd=lambd))\n",
    "            losses_test.append(log_loss(W, X_test, y_test, penalty=penalty, lambd=lambd))\n",
    "\n",
    "    if(trade):\n",
    "        return W, losses_train, losses_test\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные функции для подсчета результата.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция, результат (0 или 1) для каждого объекта из X\n",
    "def predict(W, X):\n",
    "    y_pred = softmax(X.dot(W))\n",
    "    return np.argmax(y_pred, axis=1)\n",
    "\n",
    "#функция, возвращающая долю правильных ответов на выборке X\n",
    "def accuracy(W, X, y):\n",
    "    return (predict(W, X) == np.argmax(y, axis=1)).mean()\n",
    "\n",
    "#функция, возвращающая rmse по выборке, ответам и весам\n",
    "def rmse(W, X, y):\n",
    "    y_pred = softmax(X.dot(W))\n",
    "    return np.sqrt(np.mean((y - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор фичей\n",
    "Все готово. Осталось только подобрать нужные фичи. Это нужно, так как некоторые фичи могут нести в себе ненужную информацию и только портить предсказание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая по названию фичей (словарю, где ключи - названия, а значения - true или false) добавляет нужные фичи для всех данных <br>\n",
    "Первая функция возвращет массив для данных, которые размечены. <br>\n",
    "Вторая - аналогичная функция для неразмеченных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features словарь, ключи - названия фичей, значения true или false (добавляем или не добавляем)\n",
    "def add_features_data(features):\n",
    "    result = dict_data['mean_std_channel_full']\n",
    "    result = np.hstack((result, dict_data['min_max_channel_full']))\n",
    "    result = np.hstack((result, dict_data['hog_8_8']))\n",
    "    result = np.hstack((result, dict_data['hog_4_4']))\n",
    "    if features['hist_hsv_full']:\n",
    "        result = np.hstack((result, dict_data['hist_hsv_full']))\n",
    "    if features['hist_hsv_8_8']:\n",
    "        result = np.hstack((result, dict_data['hist_hsv_8_8']))\n",
    "    if features['hist_hsv_4_4']:\n",
    "        result = np.hstack((result, dict_data['hist_hsv_4_4']))\n",
    "    if features['mean_std_channel_8_8']:\n",
    "        result = np.hstack((result, dict_data['mean_std_channel_8_8']))\n",
    "    if features['mean_std_channel_4_4']:\n",
    "        result = np.hstack((result, dict_data['mean_std_channel_4_4']))\n",
    "    if features['min_max_channel_8_8']:\n",
    "        result = np.hstack((result, dict_data['min_max_channel_8_8']))\n",
    "    if features['min_max_channel_4_4']:\n",
    "        result = np.hstack((result, dict_data['min_max_channel_4_4']))\n",
    "    if features['hist_channel_full']:\n",
    "        result = np.hstack((result, dict_data['hist_channel_full']))\n",
    "    if features['hist_channel_8_8']:\n",
    "        result = np.hstack((result, dict_data['hist_channel_8_8']))\n",
    "    if features['hist_channel_4_4']:\n",
    "        result = np.hstack((result, dict_data['hist_channel_4_4']))\n",
    "    return result.copy()\n",
    "       \n",
    "    \n",
    "def add_features_test(features):\n",
    "    result = dict_test_images['mean_std_channel_full']\n",
    "    result = np.hstack((result, dict_test_images['min_max_channel_full']))\n",
    "    result = np.hstack((result, dict_test_images['hog_8_8']))\n",
    "    result = np.hstack((result, dict_test_images['hog_4_4']))\n",
    "    if features['hist_hsv_full']:\n",
    "        result = np.hstack((result, dict_test_images['hist_hsv_full']))\n",
    "    if features['hist_hsv_8_8']:\n",
    "        result = np.hstack((result, dict_test_images['hist_hsv_8_8']))\n",
    "    if features['hist_hsv_4_4']:\n",
    "        result = np.hstack((result, dict_test_images['hist_hsv_4_4']))\n",
    "    if features['mean_std_channel_8_8']:\n",
    "        result = np.hstack((result, dict_test_images['mean_std_channel_8_8']))\n",
    "    if features['mean_std_channel_4_4']:\n",
    "        result = np.hstack((result, dict_test_images['mean_std_channel_4_4']))\n",
    "    if features['min_max_channel_8_8']:\n",
    "        result = np.hstack((result, dict_test_images['min_max_channel_8_8']))\n",
    "    if features['min_max_channel_4_4']:\n",
    "        result = np.hstack((result, dict_test_images['min_max_channel_4_4']))\n",
    "    if features['hist_channel_full']:\n",
    "        result = np.hstack((result, dict_test_images['hist_channel_full']))\n",
    "    if features['hist_channel_8_8']:\n",
    "        result = np.hstack((result, dict_test_images['hist_channel_8_8']))\n",
    "    if features['hist_channel_4_4']:\n",
    "        result = np.hstack((result, dict_test_images['hist_channel_4_4']))\n",
    "    return result.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем функцию, которая будет принимать обучающую выборку и тестовую выборку, масштабировать обе, обучаться и после возвращать rmse на тестовой и на обучающей выборках. <br> <br>\n",
    "Масштабировать нужно так как полученные признаки могут иметь разные порядки, а линейные модели с использованием регуляризации с таким плохо работают, так как при признаках разного порядка могут быть и оптимальные веса разного порядка, но большие веса мы запрещаем регуляризацией. <br>\n",
    "Также сначала нужно инициализировать матрицу W. Инициализируем ее маленькими случайными значениями.<br>\n",
    "Для имитации вектора свободных коэффициентов b добавляем к матрицам W и X по дополнительному вектору. (см ранее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_fit_rmse(train_data, train_labels, test_data, test_labels):\n",
    "    #масштабируем \n",
    "    mean = np.mean(train_data)\n",
    "    std = np.std(train_data)\n",
    "    train_data_scaled = (train_data - mean) / std\n",
    "    test_data_scaled = (test_data - mean) / std\n",
    "    \n",
    "    #размеры матриц\n",
    "    D = train_data_scaled.shape[1]\n",
    "    N = train_data_scaled.shape[0]\n",
    "    C = 2\n",
    "    \n",
    "    np.random.seed(10)\n",
    "    #инициализируем матрицу весов\n",
    "    W = np.random.randn(D, C) * 0.01\n",
    "    \n",
    "    #для имитации вектора b добавляем к матрицам W и X (train_data_scaled) по дополнительному вектору\n",
    "    W = np.concatenate((W, np.zeros((1, C))))\n",
    "    train_data_scaled = np.concatenate((train_data_scaled, np.ones((N, 1))), axis=1)\n",
    "    test_data_scaled = np.concatenate((test_data_scaled, np.ones((test_data.shape[0], 1))), axis=1)\n",
    "    \n",
    "    #обучение\n",
    "    n_iter = 900\n",
    "    W_res = gradientDescentAdam(W.copy(), train_data_scaled, train_labels, n_iter, penalty='l1')\n",
    "    \n",
    "    \n",
    "    rmse_test = rmse(W_res, test_data_scaled, test_labels)\n",
    "    rmse_train = rmse(W_res, train_data_scaled, train_labels)\n",
    "    return rmse_test, rmse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем перебор по фичам. Для каждого набора выводим rmse для обучающей выборке и для валидационной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**работает долго (часа 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True True True True True True True \n",
      " Test:  0.226127     Train:  0.095447 \n",
      "=======================\n",
      "True True True True True True True True True False \n",
      " Test:  0.225366     Train:  0.13487 \n",
      "=======================\n",
      "True True True True True True True True False True \n",
      " Test:  0.226075     Train:  0.098468 \n",
      "=======================\n",
      "True True True True True True True True False False \n",
      " Test:  0.237423     Train:  0.154752 \n",
      "=======================\n",
      "True True True True True True True False True True \n",
      " Test:  0.224641     Train:  0.095672 \n",
      "=======================\n",
      "True True True True True True True False True False \n",
      " Test:  0.224996     Train:  0.134911 \n",
      "=======================\n",
      "True True True True True True True False False True \n",
      " Test:  0.224715     Train:  0.098718 \n",
      "=======================\n",
      "True True True True True True True False False False \n",
      " Test:  0.240895     Train:  0.158722 \n",
      "=======================\n",
      "True True True True True True False True True True \n",
      " Test:  0.226194     Train:  0.09909 \n",
      "=======================\n",
      "True True True True True True False True True False \n",
      " Test:  0.225401     Train:  0.137273 \n",
      "=======================\n",
      "True True True True True True False True False True \n",
      " Test:  0.224443     Train:  0.101505 \n",
      "=======================\n",
      "True True True True True True False True False False \n",
      " Test:  0.238868     Train:  0.158969 \n",
      "=======================\n",
      "True True True True True True False False True True \n",
      " Test:  0.226248     Train:  0.098864 \n",
      "=======================\n",
      "True True True True True True False False True False \n",
      " Test:  0.225684     Train:  0.137384 \n",
      "=======================\n",
      "True True True True True True False False False True \n",
      " Test:  0.225469     Train:  0.102236 \n",
      "=======================\n",
      "True True True True True True False False False False \n",
      " Test:  0.242139     Train:  0.16353 \n",
      "=======================\n",
      "True True True True True False True True True True \n",
      " Test:  0.225052     Train:  0.096323 \n",
      "=======================\n",
      "True True True True True False True True True False \n",
      " Test:  0.225499     Train:  0.135475 \n",
      "=======================\n",
      "True True True True True False True True False True \n",
      " Test:  0.224627     Train:  0.100733 \n",
      "=======================\n",
      "True True True True True False True True False False \n",
      " Test:  0.238085     Train:  0.156084 \n",
      "=======================\n",
      "True True True True True False True False True True \n",
      " Test:  0.22627     Train:  0.09667 \n",
      "=======================\n",
      "True True True True True False True False True False \n",
      " Test:  0.225618     Train:  0.135736 \n",
      "=======================\n",
      "True True True True True False True False False True \n",
      " Test:  0.224849     Train:  0.100788 \n",
      "=======================\n",
      "True True True True True False True False False False \n",
      " Test:  0.241421     Train:  0.160026 \n",
      "=======================\n",
      "True True True True True False False True True True \n",
      " Test:  0.227077     Train:  0.098458 \n",
      "=======================\n",
      "True True True True True False False True True False \n",
      " Test:  0.225876     Train:  0.138376 \n",
      "=======================\n",
      "True True True True True False False True False True \n",
      " Test:  0.224709     Train:  0.101753 \n",
      "=======================\n",
      "True True True True True False False True False False \n",
      " Test:  0.239641     Train:  0.160515 \n",
      "=======================\n",
      "True True True True True False False False True True \n",
      " Test:  0.225609     Train:  0.098562 \n",
      "=======================\n",
      "True True True True True False False False True False \n",
      " Test:  0.226019     Train:  0.138928 \n",
      "=======================\n",
      "True True True True True False False False False True \n",
      " Test:  0.223591     Train:  0.101315 \n",
      "=======================\n",
      "True True True True True False False False False False \n",
      " Test:  0.242915     Train:  0.165411 \n",
      "=======================\n",
      "True True True True False True True True True True \n",
      " Test:  0.224782     Train:  0.099296 \n",
      "=======================\n",
      "True True True True False True True True True False \n",
      " Test:  0.225266     Train:  0.137806 \n",
      "=======================\n",
      "True True True True False True True True False True \n",
      " Test:  0.223961     Train:  0.102093 \n",
      "=======================\n",
      "True True True True False True True True False False \n",
      " Test:  0.237232     Train:  0.158969 \n",
      "=======================\n",
      "True True True True False True True False True True \n",
      " Test:  0.225122     Train:  0.09937 \n",
      "=======================\n",
      "True True True True False True True False True False \n",
      " Test:  0.225509     Train:  0.137904 \n",
      "=======================\n",
      "True True True True False True True False False True \n",
      " Test:  0.222756     Train:  0.102487 \n",
      "=======================\n",
      "True True True True False True True False False False \n",
      " Test:  0.240578     Train:  0.163823 \n",
      "=======================\n",
      "True True True True False True False True True True \n",
      " Test:  0.225064     Train:  0.100663 \n",
      "=======================\n",
      "True True True True False True False True True False \n",
      " Test:  0.22587     Train:  0.140875 \n",
      "=======================\n",
      "True True True True False True False True False True \n",
      " Test:  0.223529     Train:  0.103485 \n",
      "=======================\n",
      "True True True True False True False True False False \n",
      " Test:  0.239286     Train:  0.163762 \n",
      "=======================\n",
      "True True True True False True False False True True \n",
      " Test:  0.224141     Train:  0.10007 \n",
      "=======================\n",
      "True True True True False True False False True False \n",
      " Test:  0.226127     Train:  0.140903 \n",
      "=======================\n",
      "True True True True False True False False False True \n",
      " Test:  0.223407     Train:  0.103768 \n",
      "=======================\n",
      "True True True True False True False False False False \n",
      " Test:  0.24253     Train:  0.169397 \n",
      "=======================\n",
      "True True True True False False True True True True \n",
      " Test:  0.224505     Train:  0.098221 \n",
      "=======================\n",
      "True True True True False False True True True False \n",
      " Test:  0.225004     Train:  0.138352 \n",
      "=======================\n",
      "True True True True False False True True False True \n",
      " Test:  0.224368     Train:  0.102182 \n",
      "=======================\n",
      "True True True True False False True True False False \n",
      " Test:  0.23795     Train:  0.160264 \n",
      "=======================\n",
      "True True True True False False True False True True \n",
      " Test:  0.224402     Train:  0.098587 \n",
      "=======================\n",
      "True True True True False False True False True False \n",
      " Test:  0.225751     Train:  0.138625 \n",
      "=======================\n",
      "True True True True False False True False False True \n",
      " Test:  0.223698     Train:  0.102621 \n",
      "=======================\n",
      "True True True True False False True False False False \n",
      " Test:  0.241242     Train:  0.165264 \n",
      "=======================\n",
      "True True True True False False False True True True \n",
      " Test:  0.225109     Train:  0.102217 \n",
      "=======================\n",
      "True True True True False False False True True False \n",
      " Test:  0.226086     Train:  0.142094 \n",
      "=======================\n",
      "True True True True False False False True False True \n",
      " Test:  0.224205     Train:  0.104834 \n",
      "=======================\n",
      "True True True True False False False True False False \n",
      " Test:  0.240113     Train:  0.165425 \n",
      "=======================\n",
      "True True True True False False False False True True \n",
      " Test:  0.223809     Train:  0.102458 \n",
      "=======================\n",
      "True True True True False False False False True False \n",
      " Test:  0.226238     Train:  0.142165 \n",
      "=======================\n",
      "True True True True False False False False False True \n",
      " Test:  0.224548     Train:  0.105004 \n",
      "=======================\n",
      "True True True True False False False False False False \n",
      " Test:  0.243464     Train:  0.171403 \n",
      "=======================\n",
      "True True True False True True True True True True \n",
      " Test:  0.225133     Train:  0.097928 \n",
      "=======================\n",
      "True True True False True True True True True False \n",
      " Test:  0.225301     Train:  0.135349 \n",
      "=======================\n",
      "True True True False True True True True False True \n",
      " Test:  0.226387     Train:  0.100361 \n",
      "=======================\n",
      "True True True False True True True True False False \n",
      " Test:  0.237587     Train:  0.155823 \n",
      "=======================\n",
      "True True True False True True True False True True \n",
      " Test:  0.224676     Train:  0.097856 \n",
      "=======================\n",
      "True True True False True True True False True False \n",
      " Test:  0.225737     Train:  0.135649 \n",
      "=======================\n",
      "True True True False True True True False False True \n",
      " Test:  0.223606     Train:  0.100531 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True False True True True False False False \n",
      " Test:  0.240835     Train:  0.159787 \n",
      "=======================\n",
      "True True True False True True False True True True \n",
      " Test:  0.224604     Train:  0.097993 \n",
      "=======================\n",
      "True True True False True True False True True False \n",
      " Test:  0.226027     Train:  0.138198 \n",
      "=======================\n",
      "True True True False True True False True False True \n",
      " Test:  0.224112     Train:  0.102367 \n",
      "=======================\n",
      "True True True False True True False True False False \n",
      " Test:  0.239031     Train:  0.160176 \n",
      "=======================\n",
      "True True True False True True False False True True \n",
      " Test:  0.226095     Train:  0.098512 \n",
      "=======================\n",
      "True True True False True True False False True False \n",
      " Test:  0.226318     Train:  0.138244 \n",
      "=======================\n",
      "True True True False True True False False False True \n",
      " Test:  0.223181     Train:  0.102363 \n",
      "=======================\n",
      "True True True False True True False False False False \n",
      " Test:  0.242198     Train:  0.164875 \n",
      "=======================\n",
      "True True True False True False True True True True \n",
      " Test:  0.225496     Train:  0.097271 \n",
      "=======================\n",
      "True True True False True False True True True False \n",
      " Test:  0.225918     Train:  0.136293 \n",
      "=======================\n",
      "True True True False True False True True False True \n",
      " Test:  0.224226     Train:  0.100787 \n",
      "=======================\n",
      "True True True False True False True True False False \n",
      " Test:  0.238146     Train:  0.156999 \n",
      "=======================\n",
      "True True True False True False True False True True \n",
      " Test:  0.223578     Train:  0.097742 \n",
      "=======================\n",
      "True True True False True False True False True False \n",
      " Test:  0.226355     Train:  0.136833 \n",
      "=======================\n",
      "True True True False True False True False False True \n",
      " Test:  0.224978     Train:  0.100776 \n",
      "=======================\n",
      "True True True False True False True False False False \n",
      " Test:  0.241405     Train:  0.161029 \n",
      "=======================\n",
      "True True True False True False False True True True \n",
      " Test:  0.226889     Train:  0.099874 \n",
      "=======================\n",
      "True True True False True False False True True False \n",
      " Test:  0.226126     Train:  0.139041 \n",
      "=======================\n",
      "True True True False True False False True False True \n",
      " Test:  0.22466     Train:  0.103759 \n",
      "=======================\n",
      "True True True False True False False True False False \n",
      " Test:  0.239758     Train:  0.161681 \n",
      "=======================\n",
      "True True True False True False False False True True \n",
      " Test:  0.223916     Train:  0.100104 \n",
      "=======================\n",
      "True True True False True False False False True False \n",
      " Test:  0.226021     Train:  0.13925 \n",
      "=======================\n",
      "True True True False True False False False False True \n",
      " Test:  0.224828     Train:  0.103522 \n",
      "=======================\n",
      "True True True False True False False False False False \n",
      " Test:  0.243023     Train:  0.166735 \n",
      "=======================\n",
      "True True True False False True True True True True \n",
      " Test:  0.224353     Train:  0.099537 \n",
      "=======================\n",
      "True True True False False True True True True False \n",
      " Test:  0.224942     Train:  0.138817 \n",
      "=======================\n",
      "True True True False False True True True False True \n",
      " Test:  0.224347     Train:  0.102154 \n",
      "=======================\n",
      "True True True False False True True True False False \n",
      " Test:  0.237315     Train:  0.160121 \n",
      "=======================\n",
      "True True True False False True True False True True \n",
      " Test:  0.224865     Train:  0.099616 \n",
      "=======================\n",
      "True True True False False True True False True False \n",
      " Test:  0.22517     Train:  0.139054 \n",
      "=======================\n",
      "True True True False False True True False False True \n",
      " Test:  0.223516     Train:  0.102274 \n",
      "=======================\n",
      "True True True False False True True False False False \n",
      " Test:  0.240641     Train:  0.165366 \n",
      "=======================\n",
      "True True True False False True False True True True \n",
      " Test:  0.225294     Train:  0.102314 \n",
      "=======================\n",
      "True True True False False True False True True False \n",
      " Test:  0.226087     Train:  0.141636 \n",
      "=======================\n",
      "True True True False False True False True False True \n",
      " Test:  0.223778     Train:  0.105085 \n",
      "=======================\n",
      "True True True False False True False True False False \n",
      " Test:  0.239656     Train:  0.165224 \n",
      "=======================\n",
      "True True True False False True False False True True \n",
      " Test:  0.225388     Train:  0.102347 \n",
      "=======================\n",
      "True True True False False True False False True False \n",
      " Test:  0.225985     Train:  0.142194 \n",
      "=======================\n",
      "True True True False False True False False False True \n",
      " Test:  0.223451     Train:  0.105225 \n",
      "=======================\n",
      "True True True False False True False False False False \n",
      " Test:  0.242783     Train:  0.170949 \n",
      "=======================\n",
      "True True True False False False True True True True \n",
      " Test:  0.224487     Train:  0.100372 \n",
      "=======================\n",
      "True True True False False False True True True False \n",
      " Test:  0.225771     Train:  0.139712 \n",
      "=======================\n",
      "True True True False False False True True False True \n",
      " Test:  0.222893     Train:  0.102578 \n",
      "=======================\n",
      "True True True False False False True True False False \n",
      " Test:  0.23787     Train:  0.161153 \n",
      "=======================\n",
      "True True True False False False True False True True \n",
      " Test:  0.223382     Train:  0.100655 \n",
      "=======================\n",
      "True True True False False False True False True False \n",
      " Test:  0.225909     Train:  0.139879 \n",
      "=======================\n",
      "True True True False False False True False False True \n",
      " Test:  0.223183     Train:  0.103003 \n",
      "=======================\n",
      "True True True False False False True False False False \n",
      " Test:  0.24115     Train:  0.166468 \n",
      "=======================\n",
      "True True True False False False False True True True \n",
      " Test:  0.225967     Train:  0.102097 \n",
      "=======================\n",
      "True True True False False False False True True False \n",
      " Test:  0.226729     Train:  0.142858 \n",
      "=======================\n",
      "True True True False False False False True False True \n",
      " Test:  0.224853     Train:  0.106039 \n",
      "=======================\n",
      "True True True False False False False True False False \n",
      " Test:  0.240405     Train:  0.166739 \n",
      "=======================\n",
      "True True True False False False False False True True \n",
      " Test:  0.225462     Train:  0.102116 \n",
      "=======================\n",
      "True True True False False False False False True False \n",
      " Test:  0.226905     Train:  0.143211 \n",
      "=======================\n",
      "True True True False False False False False False True \n",
      " Test:  0.225293     Train:  0.105909 \n",
      "=======================\n",
      "True True True False False False False False False False \n",
      " Test:  0.243673     Train:  0.17316 \n",
      "=======================\n",
      "True True False True True True True True True True \n",
      " Test:  0.225763     Train:  0.095816 \n",
      "=======================\n",
      "True True False True True True True True True False \n",
      " Test:  0.226637     Train:  0.134913 \n",
      "=======================\n",
      "True True False True True True True True False True \n",
      " Test:  0.224712     Train:  0.099265 \n",
      "=======================\n",
      "True True False True True True True True False False \n",
      " Test:  0.237609     Train:  0.154823 \n",
      "=======================\n",
      "True True False True True True True False True True \n",
      " Test:  0.225463     Train:  0.095502 \n",
      "=======================\n",
      "True True False True True True True False True False \n",
      " Test:  0.226271     Train:  0.135044 \n",
      "=======================\n",
      "True True False True True True True False False True \n",
      " Test:  0.22349     Train:  0.098773 \n",
      "=======================\n",
      "True True False True True True True False False False \n",
      " Test:  0.241218     Train:  0.158887 \n",
      "=======================\n",
      "True True False True True True False True True True \n",
      " Test:  0.225376     Train:  0.098151 \n",
      "=======================\n",
      "True True False True True True False True True False \n",
      " Test:  0.226113     Train:  0.137436 \n",
      "=======================\n",
      "True True False True True True False True False True \n",
      " Test:  0.223639     Train:  0.101193 \n",
      "=======================\n",
      "True True False True True True False True False False \n",
      " Test:  0.238923     Train:  0.159392 \n",
      "=======================\n",
      "True True False True True True False False True True \n",
      " Test:  0.224598     Train:  0.098564 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True False True True True False False True False \n",
      " Test:  0.226128     Train:  0.137709 \n",
      "=======================\n",
      "True True False True True True False False False True \n",
      " Test:  0.224369     Train:  0.101957 \n",
      "=======================\n",
      "True True False True True True False False False False \n",
      " Test:  0.242333     Train:  0.164086 \n",
      "=======================\n",
      "True True False True True False True True True True \n",
      " Test:  0.225827     Train:  0.097113 \n",
      "=======================\n",
      "True True False True True False True True True False \n",
      " Test:  0.22642     Train:  0.135095 \n",
      "=======================\n",
      "True True False True True False True True False True \n",
      " Test:  0.224905     Train:  0.10044 \n",
      "=======================\n",
      "True True False True True False True True False False \n",
      " Test:  0.238164     Train:  0.156322 \n",
      "=======================\n",
      "True True False True True False True False True True \n",
      " Test:  0.225461     Train:  0.097345 \n",
      "=======================\n",
      "True True False True True False True False True False \n",
      " Test:  0.226095     Train:  0.135655 \n",
      "=======================\n",
      "True True False True True False True False False True \n",
      " Test:  0.225594     Train:  0.100507 \n",
      "=======================\n",
      "True True False True True False True False False False \n",
      " Test:  0.241814     Train:  0.160489 \n",
      "=======================\n",
      "True True False True True False False True True True \n",
      " Test:  0.225771     Train:  0.09896 \n",
      "=======================\n",
      "True True False True True False False True True False \n",
      " Test:  0.226877     Train:  0.138112 \n",
      "=======================\n",
      "True True False True True False False True False True \n",
      " Test:  0.224542     Train:  0.101391 \n",
      "=======================\n",
      "True True False True True False False True False False \n",
      " Test:  0.239594     Train:  0.160768 \n",
      "=======================\n",
      "True True False True True False False False True True \n",
      " Test:  0.224373     Train:  0.098524 \n",
      "=======================\n",
      "True True False True True False False False True False \n",
      " Test:  0.226469     Train:  0.138497 \n",
      "=======================\n",
      "True True False True True False False False False True \n",
      " Test:  0.224201     Train:  0.101397 \n",
      "=======================\n",
      "True True False True True False False False False False \n",
      " Test:  0.243101     Train:  0.165742 \n",
      "=======================\n",
      "True True False True False True True True True True \n",
      " Test:  0.224574     Train:  0.099487 \n",
      "=======================\n",
      "True True False True False True True True True False \n",
      " Test:  0.225165     Train:  0.138297 \n",
      "=======================\n",
      "True True False True False True True True False True \n",
      " Test:  0.223978     Train:  0.102349 \n",
      "=======================\n",
      "True True False True False True True True False False \n",
      " Test:  0.237481     Train:  0.159492 \n",
      "=======================\n",
      "True True False True False True True False True True \n",
      " Test:  0.225784     Train:  0.099542 \n",
      "=======================\n",
      "True True False True False True True False True False \n",
      " Test:  0.225646     Train:  0.138479 \n",
      "=======================\n",
      "True True False True False True True False False True \n",
      " Test:  0.224024     Train:  0.102755 \n",
      "=======================\n",
      "True True False True False True True False False False \n",
      " Test:  0.240976     Train:  0.164551 \n",
      "=======================\n",
      "True True False True False True False True True True \n",
      " Test:  0.225036     Train:  0.100377 \n",
      "=======================\n",
      "True True False True False True False True True False \n",
      " Test:  0.226299     Train:  0.141215 \n",
      "=======================\n",
      "True True False True False True False True False True \n",
      " Test:  0.224441     Train:  0.10489 \n",
      "=======================\n",
      "True True False True False True False True False False \n",
      " Test:  0.239275     Train:  0.16482 \n",
      "=======================\n",
      "True True False True False True False False True True \n",
      " Test:  0.224621     Train:  0.100033 \n",
      "=======================\n",
      "True True False True False True False False True False \n",
      " Test:  0.225904     Train:  0.141046 \n",
      "=======================\n",
      "True True False True False True False False False True \n",
      " Test:  0.224345     Train:  0.104702 \n",
      "=======================\n",
      "True True False True False True False False False False \n",
      " Test:  0.242745     Train:  0.170595 \n",
      "=======================\n",
      "True True False True False False True True True True \n",
      " Test:  0.225699     Train:  0.098989 \n",
      "=======================\n",
      "True True False True False False True True True False \n",
      " Test:  0.226024     Train:  0.139009 \n",
      "=======================\n",
      "True True False True False False True True False True \n",
      " Test:  0.224462     Train:  0.102343 \n",
      "=======================\n",
      "True True False True False False True True False False \n",
      " Test:  0.238006     Train:  0.160944 \n",
      "=======================\n",
      "True True False True False False True False True True \n",
      " Test:  0.225221     Train:  0.098582 \n",
      "=======================\n",
      "True True False True False False True False True False \n",
      " Test:  0.225971     Train:  0.13909 \n",
      "=======================\n",
      "True True False True False False True False False True \n",
      " Test:  0.222606     Train:  0.102377 \n",
      "=======================\n",
      "True True False True False False True False False False \n",
      " Test:  0.241514     Train:  0.166144 \n",
      "=======================\n",
      "True True False True False False False True True True \n",
      " Test:  0.225039     Train:  0.102296 \n",
      "=======================\n",
      "True True False True False False False True True False \n",
      " Test:  0.226605     Train:  0.14243 \n",
      "=======================\n",
      "True True False True False False False True False True \n",
      " Test:  0.224065     Train:  0.105988 \n",
      "=======================\n",
      "True True False True False False False True False False \n",
      " Test:  0.240088     Train:  0.166555 \n",
      "=======================\n",
      "True True False True False False False False True True \n",
      " Test:  0.225246     Train:  0.102807 \n",
      "=======================\n",
      "True True False True False False False False True False \n",
      " Test:  0.226522     Train:  0.143008 \n",
      "=======================\n",
      "True True False True False False False False False True \n",
      " Test:  0.223937     Train:  0.105906 \n",
      "=======================\n",
      "True True False True False False False False False False \n",
      " Test:  0.243548     Train:  0.172649 \n",
      "=======================\n",
      "True True False False True True True True True True \n",
      " Test:  0.224541     Train:  0.096787 \n",
      "=======================\n",
      "True True False False True True True True True False \n",
      " Test:  0.225882     Train:  0.135514 \n",
      "=======================\n",
      "True True False False True True True True False True \n",
      " Test:  0.224449     Train:  0.100442 \n",
      "=======================\n",
      "True True False False True True True True False False \n",
      " Test:  0.237687     Train:  0.156023 \n",
      "=======================\n",
      "True True False False True True True False True True \n",
      " Test:  0.22506     Train:  0.097018 \n",
      "=======================\n",
      "True True False False True True True False True False \n",
      " Test:  0.225806     Train:  0.135833 \n",
      "=======================\n",
      "True True False False True True True False False True \n",
      " Test:  0.223943     Train:  0.100122 \n",
      "=======================\n",
      "True True False False True True True False False False \n",
      " Test:  0.241121     Train:  0.160125 \n",
      "=======================\n",
      "True True False False True True False True True True \n",
      " Test:  0.225738     Train:  0.098656 \n",
      "=======================\n",
      "True True False False True True False True True False \n",
      " Test:  0.22583     Train:  0.138225 \n",
      "=======================\n",
      "True True False False True True False True False True \n",
      " Test:  0.223941     Train:  0.101592 \n",
      "=======================\n",
      "True True False False True True False True False False \n",
      " Test:  0.238925     Train:  0.160498 \n",
      "=======================\n",
      "True True False False True True False False True True \n",
      " Test:  0.225767     Train:  0.098108 \n",
      "=======================\n",
      "True True False False True True False False True False \n",
      " Test:  0.22602     Train:  0.138672 \n",
      "=======================\n",
      "True True False False True True False False False True \n",
      " Test:  0.224563     Train:  0.102138 \n",
      "=======================\n",
      "True True False False True True False False False False \n",
      " Test:  0.242347     Train:  0.165345 \n",
      "=======================\n",
      "True True False False True False True True True True \n",
      " Test:  0.226166     Train:  0.097105 \n",
      "=======================\n",
      "True True False False True False True True True False \n",
      " Test:  0.226099     Train:  0.136754 \n",
      "=======================\n",
      "True True False False True False True True False True \n",
      " Test:  0.224464     Train:  0.099398 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True False False True False True True False False \n",
      " Test:  0.238114     Train:  0.157372 \n",
      "=======================\n",
      "True True False False True False True False True True \n",
      " Test:  0.224855     Train:  0.097307 \n",
      "=======================\n",
      "True True False False True False True False True False \n",
      " Test:  0.225797     Train:  0.136896 \n",
      "=======================\n",
      "True True False False True False True False False True \n",
      " Test:  0.223937     Train:  0.099986 \n",
      "=======================\n",
      "True True False False True False True False False False \n",
      " Test:  0.241595     Train:  0.161527 \n",
      "=======================\n",
      "True True False False True False False True True True \n",
      " Test:  0.224694     Train:  0.100187 \n",
      "=======================\n",
      "True True False False True False False True True False \n",
      " Test:  0.225912     Train:  0.139436 \n",
      "=======================\n",
      "True True False False True False False True False True \n",
      " Test:  0.224724     Train:  0.102694 \n",
      "=======================\n",
      "True True False False True False False True False False \n",
      " Test:  0.239829     Train:  0.162218 \n",
      "=======================\n",
      "True True False False True False False False True True \n",
      " Test:  0.224576     Train:  0.099803 \n",
      "=======================\n",
      "True True False False True False False False True False \n",
      " Test:  0.226363     Train:  0.139718 \n",
      "=======================\n",
      "True True False False True False False False False True \n",
      " Test:  0.224185     Train:  0.102726 \n",
      "=======================\n",
      "True True False False True False False False False False \n",
      " Test:  0.24323     Train:  0.167433 \n",
      "=======================\n",
      "True True False False False True True True True True \n",
      " Test:  0.224463     Train:  0.098104 \n",
      "=======================\n",
      "True True False False False True True True True False \n",
      " Test:  0.225486     Train:  0.139014 \n",
      "=======================\n",
      "True True False False False True True True False True \n",
      " Test:  0.224148     Train:  0.102945 \n",
      "=======================\n",
      "True True False False False True True True False False \n",
      " Test:  0.237481     Train:  0.160661 \n",
      "=======================\n",
      "True True False False False True True False True True \n",
      " Test:  0.22351     Train:  0.098758 \n",
      "=======================\n",
      "True True False False False True True False True False \n",
      " Test:  0.22461     Train:  0.139306 \n",
      "=======================\n",
      "True True False False False True True False False True \n",
      " Test:  0.223909     Train:  0.102901 \n",
      "=======================\n",
      "True True False False False True True False False False \n",
      " Test:  0.240867     Train:  0.166054 \n",
      "=======================\n",
      "True True False False False True False True True True \n",
      " Test:  0.225019     Train:  0.101925 \n",
      "=======================\n",
      "True True False False False True False True True False \n",
      " Test:  0.226092     Train:  0.142649 \n",
      "=======================\n",
      "True True False False False True False True False True \n",
      " Test:  0.223543     Train:  0.105761 \n",
      "=======================\n",
      "True True False False False True False True False False \n",
      " Test:  0.239396     Train:  0.166263 \n",
      "=======================\n",
      "True True False False False True False False True True \n",
      " Test:  0.224492     Train:  0.101876 \n",
      "=======================\n",
      "True True False False False True False False True False \n",
      " Test:  0.22564     Train:  0.143014 \n",
      "=======================\n",
      "True True False False False True False False False True \n",
      " Test:  0.22393     Train:  0.105656 \n",
      "=======================\n",
      "True True False False False True False False False False \n",
      " Test:  0.242823     Train:  0.172373 \n",
      "=======================\n",
      "True True False False False False True True True True \n",
      " Test:  0.225372     Train:  0.100328 \n",
      "=======================\n",
      "True True False False False False True True True False \n",
      " Test:  0.225668     Train:  0.139657 \n",
      "=======================\n",
      "True True False False False False True True False True \n",
      " Test:  0.224269     Train:  0.10315 \n",
      "=======================\n",
      "True True False False False False True True False False \n",
      " Test:  0.237938     Train:  0.162108 \n",
      "=======================\n",
      "True True False False False False True False True True \n",
      " Test:  0.224706     Train:  0.100857 \n",
      "=======================\n",
      "True True False False False False True False True False \n",
      " Test:  0.225914     Train:  0.140045 \n",
      "=======================\n",
      "True True False False False False True False False True \n",
      " Test:  0.22311     Train:  0.104071 \n",
      "=======================\n",
      "True True False False False False True False False False \n",
      " Test:  0.241393     Train:  0.16752 \n",
      "=======================\n",
      "True True False False False False False True True True \n",
      " Test:  0.22611     Train:  0.103394 \n",
      "=======================\n",
      "True True False False False False False True True False \n",
      " Test:  0.2263     Train:  0.143667 \n",
      "=======================\n",
      "True True False False False False False True False True \n",
      " Test:  0.224874     Train:  0.106936 \n",
      "=======================\n",
      "True True False False False False False True False False \n",
      " Test:  0.240149     Train:  0.168032 \n",
      "=======================\n",
      "True True False False False False False False True True \n",
      " Test:  0.225806     Train:  0.10316 \n",
      "=======================\n",
      "True True False False False False False False True False \n",
      " Test:  0.226585     Train:  0.143948 \n",
      "=======================\n",
      "True True False False False False False False False True \n",
      " Test:  0.22551     Train:  0.106783 \n",
      "=======================\n",
      "True True False False False False False False False False \n",
      " Test:  0.243607     Train:  0.174593 \n",
      "=======================\n",
      "True False True True True True True True True True \n",
      " Test:  0.225654     Train:  0.118066 \n",
      "=======================\n",
      "True False True True True True True True True False \n",
      " Test:  0.220533     Train:  0.16081 \n",
      "=======================\n",
      "True False True True True True True True False True \n",
      " Test:  0.224852     Train:  0.121995 \n",
      "=======================\n",
      "True False True True True True True True False False \n",
      " Test:  0.231689     Train:  0.18126 \n",
      "=======================\n",
      "True False True True True True True False True True \n",
      " Test:  0.225733     Train:  0.117384 \n",
      "=======================\n",
      "True False True True True True True False True False \n",
      " Test:  0.220084     Train:  0.160485 \n",
      "=======================\n",
      "True False True True True True True False False True \n",
      " Test:  0.22432     Train:  0.121842 \n",
      "=======================\n",
      "True False True True True True True False False False \n",
      " Test:  0.234428     Train:  0.185222 \n",
      "=======================\n",
      "True False True True True True False True True True \n",
      " Test:  0.224648     Train:  0.121445 \n",
      "=======================\n",
      "True False True True True True False True True False \n",
      " Test:  0.221192     Train:  0.164025 \n",
      "=======================\n",
      "True False True True True True False True False True \n",
      " Test:  0.223777     Train:  0.123851 \n",
      "=======================\n",
      "True False True True True True False True False False \n",
      " Test:  0.235257     Train:  0.186331 \n",
      "=======================\n",
      "True False True True True True False False True True \n",
      " Test:  0.224306     Train:  0.12138 \n",
      "=======================\n",
      "True False True True True True False False True False \n",
      " Test:  0.220535     Train:  0.164175 \n",
      "=======================\n",
      "True False True True True True False False False True \n",
      " Test:  0.222342     Train:  0.124606 \n",
      "=======================\n",
      "True False True True True True False False False False \n",
      " Test:  0.237683     Train:  0.191292 \n",
      "=======================\n",
      "True False True True True False True True True True \n",
      " Test:  0.225817     Train:  0.119993 \n",
      "=======================\n",
      "True False True True True False True True True False \n",
      " Test:  0.220862     Train:  0.161926 \n",
      "=======================\n",
      "True False True True True False True True False True \n",
      " Test:  0.22366     Train:  0.123063 \n",
      "=======================\n",
      "True False True True True False True True False False \n",
      " Test:  0.232861     Train:  0.182898 \n",
      "=======================\n",
      "True False True True True False True False True True \n",
      " Test:  0.225105     Train:  0.120241 \n",
      "=======================\n",
      "True False True True True False True False True False \n",
      " Test:  0.220689     Train:  0.162431 \n",
      "=======================\n",
      "True False True True True False True False False True \n",
      " Test:  0.223469     Train:  0.122808 \n",
      "=======================\n",
      "True False True True True False True False False False \n",
      " Test:  0.235428     Train:  0.186947 \n",
      "=======================\n",
      "True False True True True False False True True True \n",
      " Test:  0.226294     Train:  0.122409 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False True True True False False True True False \n",
      " Test:  0.221537     Train:  0.164855 \n",
      "=======================\n",
      "True False True True True False False True False True \n",
      " Test:  0.222652     Train:  0.126364 \n",
      "=======================\n",
      "True False True True True False False True False False \n",
      " Test:  0.236589     Train:  0.188247 \n",
      "=======================\n",
      "True False True True True False False False True True \n",
      " Test:  0.225223     Train:  0.122333 \n",
      "=======================\n",
      "True False True True True False False False True False \n",
      " Test:  0.221189     Train:  0.165171 \n",
      "=======================\n",
      "True False True True True False False False False True \n",
      " Test:  0.223731     Train:  0.126405 \n",
      "=======================\n",
      "True False True True True False False False False False \n",
      " Test:  0.239122     Train:  0.193537 \n",
      "=======================\n",
      "True False True True False True True True True True \n",
      " Test:  0.223975     Train:  0.121833 \n",
      "=======================\n",
      "True False True True False True True True True False \n",
      " Test:  0.220685     Train:  0.164153 \n",
      "=======================\n",
      "True False True True False True True True False True \n",
      " Test:  0.223961     Train:  0.124723 \n",
      "=======================\n",
      "True False True True False True True True False False \n",
      " Test:  0.233753     Train:  0.186518 \n",
      "=======================\n",
      "True False True True False True True False True True \n",
      " Test:  0.223663     Train:  0.121564 \n",
      "=======================\n",
      "True False True True False True True False True False \n",
      " Test:  0.220121     Train:  0.164466 \n",
      "=======================\n",
      "True False True True False True True False False True \n",
      " Test:  0.22183     Train:  0.124959 \n",
      "=======================\n",
      "True False True True False True True False False False \n",
      " Test:  0.236034     Train:  0.191856 \n",
      "=======================\n",
      "True False True True False True False True True True \n",
      " Test:  0.223423     Train:  0.12528 \n",
      "=======================\n",
      "True False True True False True False True True False \n",
      " Test:  0.221903     Train:  0.167781 \n",
      "=======================\n",
      "True False True True False True False True False True \n",
      " Test:  0.22436     Train:  0.127654 \n",
      "=======================\n",
      "True False True True False True False True False False \n",
      " Test:  0.238362     Train:  0.192904 \n",
      "=======================\n",
      "True False True True False True False False True True \n",
      " Test:  0.224401     Train:  0.125154 \n",
      "=======================\n",
      "True False True True False True False False True False \n",
      " Test:  0.221541     Train:  0.167884 \n",
      "=======================\n",
      "True False True True False True False False False True \n",
      " Test:  0.223816     Train:  0.12759 \n",
      "=======================\n",
      "True False True True False True False False False False \n",
      " Test:  0.240948     Train:  0.199304 \n",
      "=======================\n",
      "True False True True False False True True True True \n",
      " Test:  0.224435     Train:  0.123641 \n",
      "=======================\n",
      "True False True True False False True True True False \n",
      " Test:  0.220563     Train:  0.165489 \n",
      "=======================\n",
      "True False True True False False True True False True \n",
      " Test:  0.222159     Train:  0.126529 \n",
      "=======================\n",
      "True False True True False False True True False False \n",
      " Test:  0.234829     Train:  0.188079 \n",
      "=======================\n",
      "True False True True False False True False True True \n",
      " Test:  0.224174     Train:  0.123733 \n",
      "=======================\n",
      "True False True True False False True False True False \n",
      " Test:  0.221091     Train:  0.165597 \n",
      "=======================\n",
      "True False True True False False True False False True \n",
      " Test:  0.221893     Train:  0.126809 \n",
      "=======================\n",
      "True False True True False False True False False False \n",
      " Test:  0.237266     Train:  0.193526 \n",
      "=======================\n",
      "True False True True False False False True True True \n",
      " Test:  0.225662     Train:  0.124806 \n",
      "=======================\n",
      "True False True True False False False True True False \n",
      " Test:  0.221687     Train:  0.168442 \n",
      "=======================\n",
      "True False True True False False False True False True \n",
      " Test:  0.22289     Train:  0.128583 \n",
      "=======================\n",
      "True False True True False False False True False False \n",
      " Test:  0.239732     Train:  0.194853 \n",
      "=======================\n",
      "True False True True False False False False True True \n",
      " Test:  0.223267     Train:  0.124918 \n",
      "=======================\n",
      "True False True True False False False False True False \n",
      " Test:  0.221702     Train:  0.168796 \n",
      "=======================\n",
      "True False True True False False False False False True \n",
      " Test:  0.222002     Train:  0.128401 \n",
      "=======================\n",
      "True False True True False False False False False False \n",
      " Test:  0.242447     Train:  0.201674 \n",
      "=======================\n",
      "True False True False True True True True True True \n",
      " Test:  0.225163     Train:  0.119563 \n",
      "=======================\n",
      "True False True False True True True True True False \n",
      " Test:  0.220492     Train:  0.161732 \n",
      "=======================\n",
      "True False True False True True True True False True \n",
      " Test:  0.223236     Train:  0.122449 \n",
      "=======================\n",
      "True False True False True True True True False False \n",
      " Test:  0.23224     Train:  0.182435 \n",
      "=======================\n",
      "True False True False True True True False True True \n",
      " Test:  0.225076     Train:  0.119604 \n",
      "=======================\n",
      "True False True False True True True False True False \n",
      " Test:  0.219923     Train:  0.162051 \n",
      "=======================\n",
      "True False True False True True True False False True \n",
      " Test:  0.223853     Train:  0.122394 \n",
      "=======================\n",
      "True False True False True True True False False False \n",
      " Test:  0.234735     Train:  0.186596 \n",
      "=======================\n",
      "True False True False True True False True True True \n",
      " Test:  0.223539     Train:  0.120683 \n",
      "=======================\n",
      "True False True False True True False True True False \n",
      " Test:  0.220518     Train:  0.164423 \n",
      "=======================\n",
      "True False True False True True False True False True \n",
      " Test:  0.224844     Train:  0.12518 \n",
      "=======================\n",
      "True False True False True True False True False False \n",
      " Test:  0.235832     Train:  0.187798 \n",
      "=======================\n",
      "True False True False True True False False True True \n",
      " Test:  0.224136     Train:  0.120674 \n",
      "=======================\n",
      "True False True False True True False False True False \n",
      " Test:  0.220916     Train:  0.164745 \n",
      "=======================\n",
      "True False True False True True False False False True \n",
      " Test:  0.224231     Train:  0.124923 \n",
      "=======================\n",
      "True False True False True True False False False False \n",
      " Test:  0.2383     Train:  0.193024 \n",
      "=======================\n",
      "True False True False True False True True True True \n",
      " Test:  0.226965     Train:  0.119952 \n",
      "=======================\n",
      "True False True False True False True True True False \n",
      " Test:  0.221004     Train:  0.16232 \n",
      "=======================\n",
      "True False True False True False True True False True \n",
      " Test:  0.224802     Train:  0.12377 \n",
      "=======================\n",
      "True False True False True False True True False False \n",
      " Test:  0.233317     Train:  0.183908 \n",
      "=======================\n",
      "True False True False True False True False True True \n",
      " Test:  0.226016     Train:  0.120015 \n",
      "=======================\n",
      "True False True False True False True False True False \n",
      " Test:  0.221018     Train:  0.162784 \n",
      "=======================\n",
      "True False True False True False True False False True \n",
      " Test:  0.224823     Train:  0.123624 \n",
      "=======================\n",
      "True False True False True False True False False False \n",
      " Test:  0.235768     Train:  0.188224 \n",
      "=======================\n",
      "True False True False True False False True True True \n",
      " Test:  0.22442     Train:  0.122804 \n",
      "=======================\n",
      "True False True False True False False True True False \n",
      " Test:  0.221765     Train:  0.165877 \n",
      "=======================\n",
      "True False True False True False False True False True \n",
      " Test:  0.223368     Train:  0.126691 \n",
      "=======================\n",
      "True False True False True False False True False False \n",
      " Test:  0.237297     Train:  0.189784 \n",
      "=======================\n",
      "True False True False True False False False True True \n",
      " Test:  0.224732     Train:  0.122921 \n",
      "=======================\n",
      "True False True False True False False False True False \n",
      " Test:  0.221248     Train:  0.166242 \n",
      "=======================\n",
      "True False True False True False False False False True \n",
      " Test:  0.223519     Train:  0.126643 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False True False True False False False False False \n",
      " Test:  0.239811     Train:  0.195365 \n",
      "=======================\n",
      "True False True False False True True True True True \n",
      " Test:  0.225219     Train:  0.122287 \n",
      "=======================\n",
      "True False True False False True True True True False \n",
      " Test:  0.220234     Train:  0.164753 \n",
      "=======================\n",
      "True False True False False True True True False True \n",
      " Test:  0.223541     Train:  0.125652 \n",
      "=======================\n",
      "True False True False False True True True False False \n",
      " Test:  0.234426     Train:  0.187899 \n",
      "=======================\n",
      "True False True False False True True False True True \n",
      " Test:  0.225268     Train:  0.122006 \n",
      "=======================\n",
      "True False True False False True True False True False \n",
      " Test:  0.220492     Train:  0.165125 \n",
      "=======================\n",
      "True False True False False True True False False True \n",
      " Test:  0.223406     Train:  0.125464 \n",
      "=======================\n",
      "True False True False False True True False False False \n",
      " Test:  0.236569     Train:  0.193479 \n",
      "=======================\n",
      "True False True False False True False True True True \n",
      " Test:  0.224432     Train:  0.125673 \n",
      "=======================\n",
      "True False True False False True False True True False \n",
      " Test:  0.222008     Train:  0.168882 \n",
      "=======================\n",
      "True False True False False True False True False True \n",
      " Test:  0.221994     Train:  0.129835 \n",
      "=======================\n",
      "True False True False False True False True False False \n",
      " Test:  0.239458     Train:  0.19482 \n",
      "=======================\n",
      "True False True False False True False False True True \n",
      " Test:  0.224351     Train:  0.125642 \n",
      "=======================\n",
      "True False True False False True False False True False \n",
      " Test:  0.22167     Train:  0.169068 \n",
      "=======================\n",
      "True False True False False True False False False True \n",
      " Test:  0.222422     Train:  0.129916 \n",
      "=======================\n",
      "True False True False False True False False False False \n",
      " Test:  0.242042     Train:  0.20133 \n",
      "=======================\n",
      "True False True False False False True True True True \n",
      " Test:  0.224231     Train:  0.122917 \n",
      "=======================\n",
      "True False True False False False True True True False \n",
      " Test:  0.220368     Train:  0.166047 \n",
      "=======================\n",
      "True False True False False False True True False True \n",
      " Test:  0.222916     Train:  0.126165 \n",
      "=======================\n",
      "True False True False False False True True False False \n",
      " Test:  0.235598     Train:  0.189387 \n",
      "=======================\n",
      "True False True False False False True False True True \n",
      " Test:  0.225428     Train:  0.122982 \n",
      "=======================\n",
      "True False True False False False True False True False \n",
      " Test:  0.220851     Train:  0.166322 \n",
      "=======================\n",
      "True False True False False False True False False True \n",
      " Test:  0.223492     Train:  0.126125 \n",
      "=======================\n",
      "True False True False False False True False False False \n",
      " Test:  0.237883     Train:  0.195115 \n",
      "=======================\n",
      "True False True False False False False True True True \n",
      " Test:  0.225932     Train:  0.126213 \n",
      "=======================\n",
      "True False True False False False False True True False \n",
      " Test:  0.222377     Train:  0.16963 \n",
      "=======================\n",
      "True False True False False False False True False True \n",
      " Test:  0.224914     Train:  0.130346 \n",
      "=======================\n",
      "True False True False False False False True False False \n",
      " Test:  0.240908     Train:  0.196825 \n",
      "=======================\n",
      "True False True False False False False False True True \n",
      " Test:  0.225468     Train:  0.126314 \n",
      "=======================\n",
      "True False True False False False False False True False \n",
      " Test:  0.222446     Train:  0.170503 \n",
      "=======================\n",
      "True False True False False False False False False True \n",
      " Test:  0.223326     Train:  0.130045 \n",
      "=======================\n",
      "True False True False False False False False False False \n",
      " Test:  0.243746     Train:  0.204176 \n",
      "=======================\n",
      "True False False True True True True True True True \n",
      " Test:  0.228713     Train:  0.135477 \n",
      "=======================\n",
      "True False False True True True True True True False \n",
      " Test:  0.230883     Train:  0.18088 \n",
      "=======================\n",
      "True False False True True True True True False True \n",
      " Test:  0.227511     Train:  0.139131 \n",
      "=======================\n",
      "True False False True True True True True False False \n",
      " Test:  0.253136     Train:  0.208535 \n",
      "=======================\n",
      "True False False True True True True False True True \n",
      " Test:  0.230347     Train:  0.13656 \n",
      "=======================\n",
      "True False False True True True True False True False \n",
      " Test:  0.230539     Train:  0.181385 \n",
      "=======================\n",
      "True False False True True True True False False True \n",
      " Test:  0.229602     Train:  0.139026 \n",
      "=======================\n",
      "True False False True True True True False False False \n",
      " Test:  0.255659     Train:  0.213486 \n",
      "=======================\n",
      "True False False True True True False True True True \n",
      " Test:  0.230109     Train:  0.137941 \n",
      "=======================\n",
      "True False False True True True False True True False \n",
      " Test:  0.232796     Train:  0.185234 \n",
      "=======================\n",
      "True False False True True True False True False True \n",
      " Test:  0.228554     Train:  0.141961 \n",
      "=======================\n",
      "True False False True True True False True False False \n",
      " Test:  0.261928     Train:  0.220515 \n",
      "=======================\n",
      "True False False True True True False False True True \n",
      " Test:  0.229225     Train:  0.137703 \n",
      "=======================\n",
      "True False False True True True False False True False \n",
      " Test:  0.233011     Train:  0.185673 \n",
      "=======================\n",
      "True False False True True True False False False True \n",
      " Test:  0.229324     Train:  0.142483 \n",
      "=======================\n",
      "True False False True True True False False False False \n",
      " Test:  0.265378     Train:  0.227453 \n",
      "=======================\n",
      "True False False True True False True True True True \n",
      " Test:  0.23016     Train:  0.13584 \n",
      "=======================\n",
      "True False False True True False True True True False \n",
      " Test:  0.231307     Train:  0.181919 \n",
      "=======================\n",
      "True False False True True False True True False True \n",
      " Test:  0.229612     Train:  0.139086 \n",
      "=======================\n",
      "True False False True True False True True False False \n",
      " Test:  0.255476     Train:  0.211525 \n",
      "=======================\n",
      "True False False True True False True False True True \n",
      " Test:  0.229599     Train:  0.135983 \n",
      "=======================\n",
      "True False False True True False True False True False \n",
      " Test:  0.231449     Train:  0.182414 \n",
      "=======================\n",
      "True False False True True False True False False True \n",
      " Test:  0.22663     Train:  0.139471 \n",
      "=======================\n",
      "True False False True True False True False False False \n",
      " Test:  0.257941     Train:  0.216632 \n",
      "=======================\n",
      "True False False True True False False True True True \n",
      " Test:  0.228773     Train:  0.139025 \n",
      "=======================\n",
      "True False False True True False False True True False \n",
      " Test:  0.233692     Train:  0.186602 \n",
      "=======================\n",
      "True False False True True False False True False True \n",
      " Test:  0.22883     Train:  0.142837 \n",
      "=======================\n",
      "True False False True True False False True False False \n",
      " Test:  0.265527     Train:  0.225096 \n",
      "=======================\n",
      "True False False True True False False False True True \n",
      " Test:  0.230626     Train:  0.138906 \n",
      "=======================\n",
      "True False False True True False False False True False \n",
      " Test:  0.233702     Train:  0.186998 \n",
      "=======================\n",
      "True False False True True False False False False True \n",
      " Test:  0.228997     Train:  0.143436 \n",
      "=======================\n",
      "True False False True True False False False False False \n",
      " Test:  0.269787     Train:  0.233025 \n",
      "=======================\n",
      "True False False True False True True True True True \n",
      " Test:  0.229373     Train:  0.137535 \n",
      "=======================\n",
      "True False False True False True True True True False \n",
      " Test:  0.232526     Train:  0.185436 \n",
      "=======================\n",
      "True False False True False True True True False True \n",
      " Test:  0.229243     Train:  0.142645 \n",
      "=======================\n",
      "True False False True False True True True False False \n",
      " Test:  0.259616     Train:  0.218653 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False False True False True True False True True \n",
      " Test:  0.226863     Train:  0.137728 \n",
      "=======================\n",
      "True False False True False True True False True False \n",
      " Test:  0.232311     Train:  0.185695 \n",
      "=======================\n",
      "True False False True False True True False False True \n",
      " Test:  0.227521     Train:  0.143144 \n",
      "=======================\n",
      "True False False True False True True False False False \n",
      " Test:  0.262527     Train:  0.225365 \n",
      "=======================\n",
      "True False False True False True False True True True \n",
      " Test:  0.229331     Train:  0.140977 \n",
      "=======================\n",
      "True False False True False True False True True False \n",
      " Test:  0.236021     Train:  0.190479 \n",
      "=======================\n",
      "True False False True False True False True False True \n",
      " Test:  0.229141     Train:  0.145506 \n",
      "=======================\n",
      "True False False True False True False True False False \n",
      " Test:  0.273843     Train:  0.236552 \n",
      "=======================\n",
      "True False False True False True False False True True \n",
      " Test:  0.229161     Train:  0.141509 \n",
      "=======================\n",
      "True False False True False True False False True False \n",
      " Test:  0.235606     Train:  0.190974 \n",
      "=======================\n",
      "True False False True False True False False False True \n",
      " Test:  0.22864     Train:  0.146077 \n",
      "=======================\n",
      "True False False True False True False False False False \n",
      " Test:  0.280059     Train:  0.247174 \n",
      "=======================\n",
      "True False False True False False True True True True \n",
      " Test:  0.228168     Train:  0.139304 \n",
      "=======================\n",
      "True False False True False False True True True False \n",
      " Test:  0.232647     Train:  0.186282 \n",
      "=======================\n",
      "True False False True False False True True False True \n",
      " Test:  0.226681     Train:  0.143422 \n",
      "=======================\n",
      "True False False True False False True True False False \n",
      " Test:  0.262351     Train:  0.222437 \n",
      "=======================\n",
      "True False False True False False True False True True \n",
      " Test:  0.228999     Train:  0.139276 \n",
      "=======================\n",
      "True False False True False False True False True False \n",
      " Test:  0.232981     Train:  0.186903 \n",
      "=======================\n",
      "True False False True False False True False False True \n",
      " Test:  0.228057     Train:  0.143659 \n",
      "=======================\n",
      "True False False True False False True False False False \n",
      " Test:  0.265754     Train:  0.22973 \n",
      "=======================\n",
      "True False False True False False False True True True \n",
      " Test:  0.230801     Train:  0.14264 \n",
      "=======================\n",
      "True False False True False False False True True False \n",
      " Test:  0.235936     Train:  0.191785 \n",
      "=======================\n",
      "True False False True False False False True False True \n",
      " Test:  0.228848     Train:  0.14705 \n",
      "=======================\n",
      "True False False True False False False True False False \n",
      " Test:  0.278494     Train:  0.242231 \n",
      "=======================\n",
      "True False False True False False False False True True \n",
      " Test:  0.229261     Train:  0.143419 \n",
      "=======================\n",
      "True False False True False False False False True False \n",
      " Test:  0.236427     Train:  0.192748 \n",
      "=======================\n",
      "True False False True False False False False False True \n",
      " Test:  0.228311     Train:  0.146921 \n",
      "=======================\n",
      "True False False True False False False False False False \n",
      " Test:  0.2859     Train:  0.254308 \n",
      "=======================\n",
      "True False False False True True True True True True \n",
      " Test:  0.229352     Train:  0.135926 \n",
      "=======================\n",
      "True False False False True True True True True False \n",
      " Test:  0.231488     Train:  0.182094 \n",
      "=======================\n",
      "True False False False True True True True False True \n",
      " Test:  0.228228     Train:  0.139535 \n",
      "=======================\n",
      "True False False False True True True True False False \n",
      " Test:  0.254554     Train:  0.210612 \n",
      "=======================\n",
      "True False False False True True True False True True \n",
      " Test:  0.228282     Train:  0.136231 \n",
      "=======================\n",
      "True False False False True True True False True False \n",
      " Test:  0.231319     Train:  0.182136 \n",
      "=======================\n",
      "True False False False True True True False False True \n",
      " Test:  0.227997     Train:  0.139965 \n",
      "=======================\n",
      "True False False False True True True False False False \n",
      " Test:  0.257028     Train:  0.215787 \n",
      "=======================\n",
      "True False False False True True False True True True \n",
      " Test:  0.229599     Train:  0.138017 \n",
      "=======================\n",
      "True False False False True True False True True False \n",
      " Test:  0.233018     Train:  0.186111 \n",
      "=======================\n",
      "True False False False True True False True False True \n",
      " Test:  0.230061     Train:  0.142706 \n",
      "=======================\n",
      "True False False False True True False True False False \n",
      " Test:  0.264453     Train:  0.223864 \n",
      "=======================\n",
      "True False False False True True False False True True \n",
      " Test:  0.229792     Train:  0.138501 \n",
      "=======================\n",
      "True False False False True True False False True False \n",
      " Test:  0.233779     Train:  0.186668 \n",
      "=======================\n",
      "True False False False True True False False False True \n",
      " Test:  0.22809     Train:  0.143511 \n",
      "=======================\n",
      "True False False False True True False False False False \n",
      " Test:  0.268449     Train:  0.231649 \n",
      "=======================\n",
      "True False False False True False True True True True \n",
      " Test:  0.229579     Train:  0.136636 \n",
      "=======================\n",
      "True False False False True False True True True False \n",
      " Test:  0.232265     Train:  0.183297 \n",
      "=======================\n",
      "True False False False True False True True False True \n",
      " Test:  0.230203     Train:  0.141272 \n",
      "=======================\n",
      "True False False False True False True True False False \n",
      " Test:  0.256845     Train:  0.213553 \n",
      "=======================\n",
      "True False False False True False True False True True \n",
      " Test:  0.229563     Train:  0.136942 \n",
      "=======================\n",
      "True False False False True False True False True False \n",
      " Test:  0.233009     Train:  0.183859 \n",
      "=======================\n",
      "True False False False True False True False False True \n",
      " Test:  0.227537     Train:  0.141878 \n",
      "=======================\n",
      "True False False False True False True False False False \n",
      " Test:  0.259338     Train:  0.218911 \n",
      "=======================\n",
      "True False False False True False False True True True \n",
      " Test:  0.228987     Train:  0.139299 \n",
      "=======================\n",
      "True False False False True False False True True False \n",
      " Test:  0.233869     Train:  0.187696 \n",
      "=======================\n",
      "True False False False True False False True False True \n",
      " Test:  0.228537     Train:  0.144394 \n",
      "=======================\n",
      "True False False False True False False True False False \n",
      " Test:  0.268681     Train:  0.228999 \n",
      "=======================\n",
      "True False False False True False False False True True \n",
      " Test:  0.229264     Train:  0.139801 \n",
      "=======================\n",
      "True False False False True False False False True False \n",
      " Test:  0.234695     Train:  0.188608 \n",
      "=======================\n",
      "True False False False True False False False False True \n",
      " Test:  0.228703     Train:  0.145297 \n",
      "=======================\n",
      "True False False False True False False False False False \n",
      " Test:  0.273524     Train:  0.237906 \n",
      "=======================\n",
      "True False False False False True True True True True \n",
      " Test:  0.229645     Train:  0.139646 \n",
      "=======================\n",
      "True False False False False True True True True False \n",
      " Test:  0.232539     Train:  0.18665 \n",
      "=======================\n",
      "True False False False False True True True False True \n",
      " Test:  0.226279     Train:  0.143466 \n",
      "=======================\n",
      "True False False False False True True True False False \n",
      " Test:  0.26208     Train:  0.222153 \n",
      "=======================\n",
      "True False False False False True True False True True \n",
      " Test:  0.227401     Train:  0.140191 \n",
      "=======================\n",
      "True False False False False True True False True False \n",
      " Test:  0.232779     Train:  0.186985 \n",
      "=======================\n",
      "True False False False False True True False False True \n",
      " Test:  0.227997     Train:  0.14353 \n",
      "=======================\n",
      "True False False False False True True False False False \n",
      " Test:  0.265086     Train:  0.22926 \n",
      "=======================\n",
      "True False False False False True False True True True \n",
      " Test:  0.228452     Train:  0.14246 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False False False False True False True True False \n",
      " Test:  0.234715     Train:  0.191749 \n",
      "=======================\n",
      "True False False False False True False True False True \n",
      " Test:  0.228048     Train:  0.147566 \n",
      "=======================\n",
      "True False False False False True False True False False \n",
      " Test:  0.278272     Train:  0.242198 \n",
      "=======================\n",
      "True False False False False True False False True True \n",
      " Test:  0.228606     Train:  0.143733 \n",
      "=======================\n",
      "True False False False False True False False True False \n",
      " Test:  0.235176     Train:  0.192886 \n",
      "=======================\n",
      "True False False False False True False False False True \n",
      " Test:  0.229579     Train:  0.147768 \n",
      "=======================\n",
      "True False False False False True False False False False \n",
      " Test:  0.284936     Train:  0.253179 \n",
      "=======================\n",
      "True False False False False False True True True True \n",
      " Test:  0.227836     Train:  0.139792 \n",
      "=======================\n",
      "True False False False False False True True True False \n",
      " Test:  0.233369     Train:  0.187638 \n",
      "=======================\n",
      "True False False False False False True True False True \n",
      " Test:  0.229019     Train:  0.144176 \n",
      "=======================\n",
      "True False False False False False True True False False \n",
      " Test:  0.265302     Train:  0.226128 \n",
      "=======================\n",
      "True False False False False False True False True True \n",
      " Test:  0.227782     Train:  0.139096 \n",
      "=======================\n",
      "True False False False False False True False True False \n",
      " Test:  0.233988     Train:  0.188332 \n",
      "=======================\n",
      "True False False False False False True False False True \n",
      " Test:  0.226649     Train:  0.144736 \n",
      "=======================\n",
      "True False False False False False True False False False \n",
      " Test:  0.26898     Train:  0.233913 \n",
      "=======================\n",
      "True False False False False False False True True True \n",
      " Test:  0.228409     Train:  0.143413 \n",
      "=======================\n",
      "True False False False False False False True True False \n",
      " Test:  0.236921     Train:  0.193639 \n",
      "=======================\n",
      "True False False False False False False True False True \n",
      " Test:  0.228644     Train:  0.147509 \n",
      "=======================\n",
      "True False False False False False False True False False \n",
      " Test:  0.28372     Train:  0.249306 \n",
      "=======================\n",
      "True False False False False False False False True True \n",
      " Test:  0.23024     Train:  0.143637 \n",
      "=======================\n",
      "True False False False False False False False True False \n",
      " Test:  0.237235     Train:  0.194657 \n",
      "=======================\n",
      "True False False False False False False False False True \n",
      " Test:  0.229998     Train:  0.148396 \n",
      "=======================\n",
      "True False False False False False False False False False \n",
      " Test:  0.292834     Train:  0.263599 \n",
      "=======================\n",
      "False True True True True True True True True True \n",
      " Test:  0.227615     Train:  0.096873 \n",
      "=======================\n",
      "False True True True True True True True True False \n",
      " Test:  0.226248     Train:  0.135595 \n",
      "=======================\n",
      "False True True True True True True True False True \n",
      " Test:  0.226434     Train:  0.098935 \n",
      "=======================\n",
      "False True True True True True True True False False \n",
      " Test:  0.238447     Train:  0.155286 \n",
      "=======================\n",
      "False True True True True True True False True True \n",
      " Test:  0.226903     Train:  0.096822 \n",
      "=======================\n",
      "False True True True True True True False True False \n",
      " Test:  0.226302     Train:  0.135453 \n",
      "=======================\n",
      "False True True True True True True False False True \n",
      " Test:  0.226372     Train:  0.099315 \n",
      "=======================\n",
      "False True True True True True True False False False \n",
      " Test:  0.241499     Train:  0.15916 \n",
      "=======================\n",
      "False True True True True True False True True True \n",
      " Test:  0.226646     Train:  0.099394 \n",
      "=======================\n",
      "False True True True True True False True True False \n",
      " Test:  0.226486     Train:  0.138056 \n",
      "=======================\n",
      "False True True True True True False True False True \n",
      " Test:  0.226996     Train:  0.102825 \n",
      "=======================\n",
      "False True True True True True False True False False \n",
      " Test:  0.239868     Train:  0.159358 \n",
      "=======================\n",
      "False True True True True True False False True True \n",
      " Test:  0.227246     Train:  0.100211 \n",
      "=======================\n",
      "False True True True True True False False True False \n",
      " Test:  0.227089     Train:  0.138362 \n",
      "=======================\n",
      "False True True True True True False False False True \n",
      " Test:  0.225538     Train:  0.102792 \n",
      "=======================\n",
      "False True True True True True False False False False \n",
      " Test:  0.242904     Train:  0.163989 \n",
      "=======================\n",
      "False True True True True False True True True True \n",
      " Test:  0.226091     Train:  0.098285 \n",
      "=======================\n",
      "False True True True True False True True True False \n",
      " Test:  0.227164     Train:  0.136004 \n",
      "=======================\n",
      "False True True True True False True True False True \n",
      " Test:  0.225328     Train:  0.101945 \n",
      "=======================\n",
      "False True True True True False True True False False \n",
      " Test:  0.238928     Train:  0.156245 \n",
      "=======================\n",
      "False True True True True False True False True True \n",
      " Test:  0.22591     Train:  0.098225 \n",
      "=======================\n",
      "False True True True True False True False True False \n",
      " Test:  0.227042     Train:  0.136475 \n",
      "=======================\n",
      "False True True True True False True False False True \n",
      " Test:  0.225701     Train:  0.10194 \n",
      "=======================\n",
      "False True True True True False True False False False \n",
      " Test:  0.242165     Train:  0.160343 \n",
      "=======================\n",
      "False True True True True False False True True True \n",
      " Test:  0.227342     Train:  0.098737 \n",
      "=======================\n",
      "False True True True True False False True True False \n",
      " Test:  0.227224     Train:  0.138955 \n",
      "=======================\n",
      "False True True True True False False True False True \n",
      " Test:  0.22497     Train:  0.101796 \n",
      "=======================\n",
      "False True True True True False False True False False \n",
      " Test:  0.240553     Train:  0.160769 \n",
      "=======================\n",
      "False True True True True False False False True True \n",
      " Test:  0.227361     Train:  0.099189 \n",
      "=======================\n",
      "False True True True True False False False True False \n",
      " Test:  0.227524     Train:  0.139409 \n",
      "=======================\n",
      "False True True True True False False False False True \n",
      " Test:  0.22374     Train:  0.10258 \n",
      "=======================\n",
      "False True True True True False False False False False \n",
      " Test:  0.243725     Train:  0.165766 \n",
      "=======================\n",
      "False True True True False True True True True True \n",
      " Test:  0.225635     Train:  0.100667 \n",
      "=======================\n",
      "False True True True False True True True True False \n",
      " Test:  0.226443     Train:  0.138456 \n",
      "=======================\n",
      "False True True True False True True True False True \n",
      " Test:  0.225093     Train:  0.103636 \n",
      "=======================\n",
      "False True True True False True True True False False \n",
      " Test:  0.238332     Train:  0.159424 \n",
      "=======================\n",
      "False True True True False True True False True True \n",
      " Test:  0.225849     Train:  0.100774 \n",
      "=======================\n",
      "False True True True False True True False True False \n",
      " Test:  0.226345     Train:  0.138807 \n",
      "=======================\n",
      "False True True True False True True False False True \n",
      " Test:  0.224734     Train:  0.103211 \n",
      "=======================\n",
      "False True True True False True True False False False \n",
      " Test:  0.241529     Train:  0.164348 \n",
      "=======================\n",
      "False True True True False True False True True True \n",
      " Test:  0.225494     Train:  0.100562 \n",
      "=======================\n",
      "False True True True False True False True True False \n",
      " Test:  0.226877     Train:  0.14149 \n",
      "=======================\n",
      "False True True True False True False True False True \n",
      " Test:  0.22556     Train:  0.105268 \n",
      "=======================\n",
      "False True True True False True False True False False \n",
      " Test:  0.24048     Train:  0.164198 \n",
      "=======================\n",
      "False True True True False True False False True True \n",
      " Test:  0.224239     Train:  0.101277 \n",
      "=======================\n",
      "False True True True False True False False True False \n",
      " Test:  0.226813     Train:  0.141842 \n",
      "=======================\n",
      "False True True True False True False False False True \n",
      " Test:  0.225203     Train:  0.105007 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True True True False True False False False False \n",
      " Test:  0.243576     Train:  0.169852 \n",
      "=======================\n",
      "False True True True False False True True True True \n",
      " Test:  0.22692     Train:  0.099302 \n",
      "=======================\n",
      "False True True True False False True True True False \n",
      " Test:  0.226189     Train:  0.139123 \n",
      "=======================\n",
      "False True True True False False True True False True \n",
      " Test:  0.225156     Train:  0.102972 \n",
      "=======================\n",
      "False True True True False False True True False False \n",
      " Test:  0.239058     Train:  0.160558 \n",
      "=======================\n",
      "False True True True False False True False True True \n",
      " Test:  0.226543     Train:  0.098875 \n",
      "=======================\n",
      "False True True True False False True False True False \n",
      " Test:  0.226429     Train:  0.139642 \n",
      "=======================\n",
      "False True True True False False True False False True \n",
      " Test:  0.225598     Train:  0.103056 \n",
      "=======================\n",
      "False True True True False False True False False False \n",
      " Test:  0.24221     Train:  0.165645 \n",
      "=======================\n",
      "False True True True False False False True True True \n",
      " Test:  0.226351     Train:  0.103304 \n",
      "=======================\n",
      "False True True True False False False True True False \n",
      " Test:  0.226818     Train:  0.142488 \n",
      "=======================\n",
      "False True True True False False False True False True \n",
      " Test:  0.225125     Train:  0.106172 \n",
      "=======================\n",
      "False True True True False False False True False False \n",
      " Test:  0.241102     Train:  0.165678 \n",
      "=======================\n",
      "False True True True False False False False True True \n",
      " Test:  0.226062     Train:  0.102899 \n",
      "=======================\n",
      "False True True True False False False False True False \n",
      " Test:  0.227311     Train:  0.142706 \n",
      "=======================\n",
      "False True True True False False False False False True \n",
      " Test:  0.225267     Train:  0.106305 \n",
      "=======================\n",
      "False True True True False False False False False False \n",
      " Test:  0.244436     Train:  0.171727 \n",
      "=======================\n",
      "False True True False True True True True True True \n",
      " Test:  0.227687     Train:  0.097827 \n",
      "=======================\n",
      "False True True False True True True True True False \n",
      " Test:  0.226422     Train:  0.13601 \n",
      "=======================\n",
      "False True True False True True True True False True \n",
      " Test:  0.227082     Train:  0.101044 \n",
      "=======================\n",
      "False True True False True True True True False False \n",
      " Test:  0.238674     Train:  0.155968 \n",
      "=======================\n",
      "False True True False True True True False True True \n",
      " Test:  0.226509     Train:  0.098396 \n",
      "=======================\n",
      "False True True False True True True False True False \n",
      " Test:  0.226375     Train:  0.136282 \n",
      "=======================\n",
      "False True True False True True True False False True \n",
      " Test:  0.225901     Train:  0.101211 \n",
      "=======================\n",
      "False True True False True True True False False False \n",
      " Test:  0.241644     Train:  0.160022 \n",
      "=======================\n",
      "False True True False True True False True True True \n",
      " Test:  0.22479     Train:  0.099353 \n",
      "=======================\n",
      "False True True False True True False True True False \n",
      " Test:  0.226667     Train:  0.138679 \n",
      "=======================\n",
      "False True True False True True False True False True \n",
      " Test:  0.224307     Train:  0.102111 \n",
      "=======================\n",
      "False True True False True True False True False False \n",
      " Test:  0.240076     Train:  0.16048 \n",
      "=======================\n",
      "False True True False True True False False True True \n",
      " Test:  0.227472     Train:  0.100006 \n",
      "=======================\n",
      "False True True False True True False False True False \n",
      " Test:  0.226894     Train:  0.139224 \n",
      "=======================\n",
      "False True True False True True False False False True \n",
      " Test:  0.224769     Train:  0.102723 \n",
      "=======================\n",
      "False True True False True True False False False False \n",
      " Test:  0.243092     Train:  0.165177 \n",
      "=======================\n",
      "False True True False True False True True True True \n",
      " Test:  0.226001     Train:  0.097678 \n",
      "=======================\n",
      "False True True False True False True True True False \n",
      " Test:  0.226475     Train:  0.137277 \n",
      "=======================\n",
      "False True True False True False True True False True \n",
      " Test:  0.226418     Train:  0.100512 \n",
      "=======================\n",
      "False True True False True False True True False False \n",
      " Test:  0.239174     Train:  0.15734 \n",
      "=======================\n",
      "False True True False True False True False True True \n",
      " Test:  0.226004     Train:  0.097588 \n",
      "=======================\n",
      "False True True False True False True False True False \n",
      " Test:  0.227192     Train:  0.137526 \n",
      "=======================\n",
      "False True True False True False True False False True \n",
      " Test:  0.225795     Train:  0.101511 \n",
      "=======================\n",
      "False True True False True False True False False False \n",
      " Test:  0.242147     Train:  0.161379 \n",
      "=======================\n",
      "False True True False True False False True True True \n",
      " Test:  0.227753     Train:  0.100505 \n",
      "=======================\n",
      "False True True False True False False True True False \n",
      " Test:  0.22719     Train:  0.139301 \n",
      "=======================\n",
      "False True True False True False False True False True \n",
      " Test:  0.225025     Train:  0.104009 \n",
      "=======================\n",
      "False True True False True False False True False False \n",
      " Test:  0.240797     Train:  0.161904 \n",
      "=======================\n",
      "False True True False True False False False True True \n",
      " Test:  0.226719     Train:  0.100841 \n",
      "=======================\n",
      "False True True False True False False False True False \n",
      " Test:  0.227205     Train:  0.139954 \n",
      "=======================\n",
      "False True True False True False False False False True \n",
      " Test:  0.225296     Train:  0.104014 \n",
      "=======================\n",
      "False True True False True False False False False False \n",
      " Test:  0.243908     Train:  0.166975 \n",
      "=======================\n",
      "False True True False False True True True True True \n",
      " Test:  0.22619     Train:  0.09905 \n",
      "=======================\n",
      "False True True False False True True True True False \n",
      " Test:  0.2257     Train:  0.13918 \n",
      "=======================\n",
      "False True True False False True True True False True \n",
      " Test:  0.223542     Train:  0.10249 \n",
      "=======================\n",
      "False True True False False True True True False False \n",
      " Test:  0.238433     Train:  0.160371 \n",
      "=======================\n",
      "False True True False False True True False True True \n",
      " Test:  0.225747     Train:  0.100123 \n",
      "=======================\n",
      "False True True False False True True False True False \n",
      " Test:  0.225754     Train:  0.139489 \n",
      "=======================\n",
      "False True True False False True True False False True \n",
      " Test:  0.223913     Train:  0.102952 \n",
      "=======================\n",
      "False True True False False True True False False False \n",
      " Test:  0.241558     Train:  0.1657 \n",
      "=======================\n",
      "False True True False False True False True True True \n",
      " Test:  0.225422     Train:  0.102832 \n",
      "=======================\n",
      "False True True False False True False True True False \n",
      " Test:  0.226631     Train:  0.142278 \n",
      "=======================\n",
      "False True True False False True False True False True \n",
      " Test:  0.226287     Train:  0.106067 \n",
      "=======================\n",
      "False True True False False True False True False False \n",
      " Test:  0.240658     Train:  0.165548 \n",
      "=======================\n",
      "False True True False False True False False True True \n",
      " Test:  0.225982     Train:  0.102985 \n",
      "=======================\n",
      "False True True False False True False False True False \n",
      " Test:  0.22703     Train:  0.142842 \n",
      "=======================\n",
      "False True True False False True False False False True \n",
      " Test:  0.225887     Train:  0.106606 \n",
      "=======================\n",
      "False True True False False True False False False False \n",
      " Test:  0.243765     Train:  0.171356 \n",
      "=======================\n",
      "False True True False False False True True True True \n",
      " Test:  0.225461     Train:  0.102026 \n",
      "=======================\n",
      "False True True False False False True True True False \n",
      " Test:  0.226118     Train:  0.140428 \n",
      "=======================\n",
      "False True True False False False True True False True \n",
      " Test:  0.225599     Train:  0.104647 \n",
      "=======================\n",
      "False True True False False False True True False False \n",
      " Test:  0.238904     Train:  0.161557 \n",
      "=======================\n",
      "False True True False False False True False True True \n",
      " Test:  0.22661     Train:  0.102405 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True True False False False True False True False \n",
      " Test:  0.22707     Train:  0.140673 \n",
      "=======================\n",
      "False True True False False False True False False True \n",
      " Test:  0.226282     Train:  0.104833 \n",
      "=======================\n",
      "False True True False False False True False False False \n",
      " Test:  0.24209     Train:  0.166883 \n",
      "=======================\n",
      "False True True False False False False True True True \n",
      " Test:  0.225752     Train:  0.10254 \n",
      "=======================\n",
      "False True True False False False False True True False \n",
      " Test:  0.227789     Train:  0.143643 \n",
      "=======================\n",
      "False True True False False False False True False True \n",
      " Test:  0.225994     Train:  0.106951 \n",
      "=======================\n",
      "False True True False False False False True False False \n",
      " Test:  0.241443     Train:  0.167042 \n",
      "=======================\n",
      "False True True False False False False False True True \n",
      " Test:  0.225672     Train:  0.102733 \n",
      "=======================\n",
      "False True True False False False False False True False \n",
      " Test:  0.22732     Train:  0.143604 \n",
      "=======================\n",
      "False True True False False False False False False True \n",
      " Test:  0.225735     Train:  0.106837 \n",
      "=======================\n",
      "False True True False False False False False False False \n",
      " Test:  0.244641     Train:  0.173478 \n",
      "=======================\n",
      "False True False True True True True True True True \n",
      " Test:  0.22592     Train:  0.096212 \n",
      "=======================\n",
      "False True False True True True True True True False \n",
      " Test:  0.227102     Train:  0.135223 \n",
      "=======================\n",
      "False True False True True True True True False True \n",
      " Test:  0.226489     Train:  0.099435 \n",
      "=======================\n",
      "False True False True True True True True False False \n",
      " Test:  0.238326     Train:  0.154916 \n",
      "=======================\n",
      "False True False True True True True False True True \n",
      " Test:  0.227478     Train:  0.095231 \n",
      "=======================\n",
      "False True False True True True True False True False \n",
      " Test:  0.227204     Train:  0.135195 \n",
      "=======================\n",
      "False True False True True True True False False True \n",
      " Test:  0.227243     Train:  0.099326 \n",
      "=======================\n",
      "False True False True True True True False False False \n",
      " Test:  0.241638     Train:  0.158843 \n",
      "=======================\n",
      "False True False True True True False True True True \n",
      " Test:  0.225714     Train:  0.098818 \n",
      "=======================\n",
      "False True False True True True False True True False \n",
      " Test:  0.227384     Train:  0.137933 \n",
      "=======================\n",
      "False True False True True True False True False True \n",
      " Test:  0.225421     Train:  0.101715 \n",
      "=======================\n",
      "False True False True True True False True False False \n",
      " Test:  0.239649     Train:  0.159565 \n",
      "=======================\n",
      "False True False True True True False False True True \n",
      " Test:  0.226347     Train:  0.0982 \n",
      "=======================\n",
      "False True False True True True False False True False \n",
      " Test:  0.226997     Train:  0.137997 \n",
      "=======================\n",
      "False True False True True True False False False True \n",
      " Test:  0.225188     Train:  0.102418 \n",
      "=======================\n",
      "False True False True True True False False False False \n",
      " Test:  0.242742     Train:  0.16409 \n",
      "=======================\n",
      "False True False True True False True True True True \n",
      " Test:  0.226538     Train:  0.096735 \n",
      "=======================\n",
      "False True False True True False True True True False \n",
      " Test:  0.226928     Train:  0.13553 \n",
      "=======================\n",
      "False True False True True False True True False True \n",
      " Test:  0.225414     Train:  0.100396 \n",
      "=======================\n",
      "False True False True True False True True False False \n",
      " Test:  0.239065     Train:  0.156446 \n",
      "=======================\n",
      "False True False True True False True False True True \n",
      " Test:  0.226124     Train:  0.097162 \n",
      "=======================\n",
      "False True False True True False True False True False \n",
      " Test:  0.22723     Train:  0.135819 \n",
      "=======================\n",
      "False True False True True False True False False True \n",
      " Test:  0.227346     Train:  0.100025 \n",
      "=======================\n",
      "False True False True True False True False False False \n",
      " Test:  0.242233     Train:  0.16049 \n",
      "=======================\n",
      "False True False True True False False True True True \n",
      " Test:  0.227236     Train:  0.098872 \n",
      "=======================\n",
      "False True False True True False False True True False \n",
      " Test:  0.227529     Train:  0.138377 \n",
      "=======================\n",
      "False True False True True False False True False True \n",
      " Test:  0.225859     Train:  0.101487 \n",
      "=======================\n",
      "False True False True True False False True False False \n",
      " Test:  0.240313     Train:  0.160987 \n",
      "=======================\n",
      "False True False True True False False False True True \n",
      " Test:  0.227858     Train:  0.098898 \n",
      "=======================\n",
      "False True False True True False False False True False \n",
      " Test:  0.227278     Train:  0.138776 \n",
      "=======================\n",
      "False True False True True False False False False True \n",
      " Test:  0.224773     Train:  0.102104 \n",
      "=======================\n",
      "False True False True True False False False False False \n",
      " Test:  0.243494     Train:  0.165797 \n",
      "=======================\n",
      "False True False True False True True True True True \n",
      " Test:  0.225603     Train:  0.099548 \n",
      "=======================\n",
      "False True False True False True True True True False \n",
      " Test:  0.226877     Train:  0.138605 \n",
      "=======================\n",
      "False True False True False True True True False True \n",
      " Test:  0.225904     Train:  0.102426 \n",
      "=======================\n",
      "False True False True False True True True False False \n",
      " Test:  0.238146     Train:  0.159844 \n",
      "=======================\n",
      "False True False True False True True False True True \n",
      " Test:  0.227494     Train:  0.099274 \n",
      "=======================\n",
      "False True False True False True True False True False \n",
      " Test:  0.226428     Train:  0.13916 \n",
      "=======================\n",
      "False True False True False True True False False True \n",
      " Test:  0.224084     Train:  0.102557 \n",
      "=======================\n",
      "False True False True False True True False False False \n",
      " Test:  0.241251     Train:  0.164771 \n",
      "=======================\n",
      "False True False True False True False True True True \n",
      " Test:  0.226225     Train:  0.10047 \n",
      "=======================\n",
      "False True False True False True False True True False \n",
      " Test:  0.226848     Train:  0.141334 \n",
      "=======================\n",
      "False True False True False True False True False True \n",
      " Test:  0.226209     Train:  0.104248 \n",
      "=======================\n",
      "False True False True False True False True False False \n",
      " Test:  0.240149     Train:  0.16514 \n",
      "=======================\n",
      "False True False True False True False False True True \n",
      " Test:  0.22508     Train:  0.101269 \n",
      "=======================\n",
      "False True False True False True False False True False \n",
      " Test:  0.226268     Train:  0.141993 \n",
      "=======================\n",
      "False True False True False True False False False True \n",
      " Test:  0.225268     Train:  0.104737 \n",
      "=======================\n",
      "False True False True False True False False False False \n",
      " Test:  0.243093     Train:  0.170787 \n",
      "=======================\n",
      "False True False True False False True True True True \n",
      " Test:  0.22602     Train:  0.099426 \n",
      "=======================\n",
      "False True False True False False True True True False \n",
      " Test:  0.226797     Train:  0.139209 \n",
      "=======================\n",
      "False True False True False False True True False True \n",
      " Test:  0.225144     Train:  0.102514 \n",
      "=======================\n",
      "False True False True False False True True False False \n",
      " Test:  0.23869     Train:  0.161197 \n",
      "=======================\n",
      "False True False True False False True False True True \n",
      " Test:  0.225758     Train:  0.09978 \n",
      "=======================\n",
      "False True False True False False True False True False \n",
      " Test:  0.226662     Train:  0.139703 \n",
      "=======================\n",
      "False True False True False False True False False True \n",
      " Test:  0.225051     Train:  0.103377 \n",
      "=======================\n",
      "False True False True False False True False False False \n",
      " Test:  0.241864     Train:  0.166307 \n",
      "=======================\n",
      "False True False True False False False True True True \n",
      " Test:  0.226858     Train:  0.102803 \n",
      "=======================\n",
      "False True False True False False False True True False \n",
      " Test:  0.227044     Train:  0.143359 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True False True False False False True False True \n",
      " Test:  0.225261     Train:  0.106414 \n",
      "=======================\n",
      "False True False True False False False True False False \n",
      " Test:  0.24084     Train:  0.166726 \n",
      "=======================\n",
      "False True False True False False False False True True \n",
      " Test:  0.225312     Train:  0.102943 \n",
      "=======================\n",
      "False True False True False False False False True False \n",
      " Test:  0.227501     Train:  0.143445 \n",
      "=======================\n",
      "False True False True False False False False False True \n",
      " Test:  0.225587     Train:  0.106208 \n",
      "=======================\n",
      "False True False True False False False False False False \n",
      " Test:  0.243951     Train:  0.172894 \n",
      "=======================\n",
      "False True False False True True True True True True \n",
      " Test:  0.225478     Train:  0.096932 \n",
      "=======================\n",
      "False True False False True True True True True False \n",
      " Test:  0.226711     Train:  0.135919 \n",
      "=======================\n",
      "False True False False True True True True False True \n",
      " Test:  0.2249     Train:  0.100867 \n",
      "=======================\n",
      "False True False False True True True True False False \n",
      " Test:  0.238549     Train:  0.156319 \n",
      "=======================\n",
      "False True False False True True True False True True \n",
      " Test:  0.225742     Train:  0.096564 \n",
      "=======================\n",
      "False True False False True True True False True False \n",
      " Test:  0.22778     Train:  0.136116 \n",
      "=======================\n",
      "False True False False True True True False False True \n",
      " Test:  0.22634     Train:  0.101042 \n",
      "=======================\n",
      "False True False False True True True False False False \n",
      " Test:  0.241639     Train:  0.160357 \n",
      "=======================\n",
      "False True False False True True False True True True \n",
      " Test:  0.227187     Train:  0.099553 \n",
      "=======================\n",
      "False True False False True True False True True False \n",
      " Test:  0.227124     Train:  0.138977 \n",
      "=======================\n",
      "False True False False True True False True False True \n",
      " Test:  0.224846     Train:  0.102567 \n",
      "=======================\n",
      "False True False False True True False True False False \n",
      " Test:  0.239561     Train:  0.160673 \n",
      "=======================\n",
      "False True False False True True False False True True \n",
      " Test:  0.226175     Train:  0.099995 \n",
      "=======================\n",
      "False True False False True True False False True False \n",
      " Test:  0.227357     Train:  0.139548 \n",
      "=======================\n",
      "False True False False True True False False False True \n",
      " Test:  0.224369     Train:  0.103618 \n",
      "=======================\n",
      "False True False False True True False False False False \n",
      " Test:  0.242765     Train:  0.1655 \n",
      "=======================\n",
      "False True False False True False True True True True \n",
      " Test:  0.22675     Train:  0.097149 \n",
      "=======================\n",
      "False True False False True False True True True False \n",
      " Test:  0.227623     Train:  0.136682 \n",
      "=======================\n",
      "False True False False True False True True False True \n",
      " Test:  0.225549     Train:  0.100437 \n",
      "=======================\n",
      "False True False False True False True True False False \n",
      " Test:  0.238854     Train:  0.157551 \n",
      "=======================\n",
      "False True False False True False True False True True \n",
      " Test:  0.225366     Train:  0.097247 \n",
      "=======================\n",
      "False True False False True False True False True False \n",
      " Test:  0.227382     Train:  0.137162 \n",
      "=======================\n",
      "False True False False True False True False False True \n",
      " Test:  0.225748     Train:  0.100537 \n",
      "=======================\n",
      "False True False False True False True False False False \n",
      " Test:  0.242081     Train:  0.161696 \n",
      "=======================\n",
      "False True False False True False False True True True \n",
      " Test:  0.225925     Train:  0.09991 \n",
      "=======================\n",
      "False True False False True False False True True False \n",
      " Test:  0.227797     Train:  0.139295 \n",
      "=======================\n",
      "False True False False True False False True False True \n",
      " Test:  0.226889     Train:  0.102668 \n",
      "=======================\n",
      "False True False False True False False True False False \n",
      " Test:  0.240574     Train:  0.162433 \n",
      "=======================\n",
      "False True False False True False False False True True \n",
      " Test:  0.227221     Train:  0.100288 \n",
      "=======================\n",
      "False True False False True False False False True False \n",
      " Test:  0.227639     Train:  0.140015 \n",
      "=======================\n",
      "False True False False True False False False False True \n",
      " Test:  0.225114     Train:  0.10297 \n",
      "=======================\n",
      "False True False False True False False False False False \n",
      " Test:  0.243565     Train:  0.167452 \n",
      "=======================\n",
      "False True False False False True True True True True \n",
      " Test:  0.225459     Train:  0.099085 \n",
      "=======================\n",
      "False True False False False True True True True False \n",
      " Test:  0.226106     Train:  0.139263 \n",
      "=======================\n",
      "False True False False False True True True False True \n",
      " Test:  0.224471     Train:  0.103065 \n",
      "=======================\n",
      "False True False False False True True True False False \n",
      " Test:  0.238054     Train:  0.160857 \n",
      "=======================\n",
      "False True False False False True True False True True \n",
      " Test:  0.22579     Train:  0.099279 \n",
      "=======================\n",
      "False True False False False True True False True False \n",
      " Test:  0.226784     Train:  0.139749 \n",
      "=======================\n",
      "False True False False False True True False False True \n",
      " Test:  0.224122     Train:  0.103085 \n",
      "=======================\n",
      "False True False False False True True False False False \n",
      " Test:  0.241126     Train:  0.166262 \n",
      "=======================\n",
      "False True False False False True False True True True \n",
      " Test:  0.227051     Train:  0.101655 \n",
      "=======================\n",
      "False True False False False True False True True False \n",
      " Test:  0.226735     Train:  0.142855 \n",
      "=======================\n",
      "False True False False False True False True False True \n",
      " Test:  0.224417     Train:  0.105307 \n",
      "=======================\n",
      "False True False False False True False True False False \n",
      " Test:  0.240197     Train:  0.166519 \n",
      "=======================\n",
      "False True False False False True False False True True \n",
      " Test:  0.225499     Train:  0.10194 \n",
      "=======================\n",
      "False True False False False True False False True False \n",
      " Test:  0.227071     Train:  0.143107 \n",
      "=======================\n",
      "False True False False False True False False False True \n",
      " Test:  0.225738     Train:  0.105601 \n",
      "=======================\n",
      "False True False False False True False False False False \n",
      " Test:  0.243163     Train:  0.172532 \n",
      "=======================\n",
      "False True False False False False True True True True \n",
      " Test:  0.225386     Train:  0.100238 \n",
      "=======================\n",
      "False True False False False False True True True False \n",
      " Test:  0.226753     Train:  0.14024 \n",
      "=======================\n",
      "False True False False False False True True False True \n",
      " Test:  0.22511     Train:  0.103656 \n",
      "=======================\n",
      "False True False False False False True True False False \n",
      " Test:  0.238742     Train:  0.162457 \n",
      "=======================\n",
      "False True False False False False True False True True \n",
      " Test:  0.225152     Train:  0.100167 \n",
      "=======================\n",
      "False True False False False False True False True False \n",
      " Test:  0.22612     Train:  0.140679 \n",
      "=======================\n",
      "False True False False False False True False False True \n",
      " Test:  0.22567     Train:  0.104003 \n",
      "=======================\n",
      "False True False False False False True False False False \n",
      " Test:  0.241742     Train:  0.167617 \n",
      "=======================\n",
      "False True False False False False False True True True \n",
      " Test:  0.226211     Train:  0.103312 \n",
      "=======================\n",
      "False True False False False False False True True False \n",
      " Test:  0.227407     Train:  0.144144 \n",
      "=======================\n",
      "False True False False False False False True False True \n",
      " Test:  0.22562     Train:  0.10713 \n",
      "=======================\n",
      "False True False False False False False True False False \n",
      " Test:  0.24113     Train:  0.168286 \n",
      "=======================\n",
      "False True False False False False False False True True \n",
      " Test:  0.225998     Train:  0.103214 \n",
      "=======================\n",
      "False True False False False False False False True False \n",
      " Test:  0.22756     Train:  0.14451 \n",
      "=======================\n",
      "False True False False False False False False False True \n",
      " Test:  0.224783     Train:  0.107322 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True False False False False False False False False \n",
      " Test:  0.244023     Train:  0.174825 \n",
      "=======================\n",
      "False False True True True True True True True True \n",
      " Test:  0.227297     Train:  0.117648 \n",
      "=======================\n",
      "False False True True True True True True True False \n",
      " Test:  0.220551     Train:  0.160365 \n",
      "=======================\n",
      "False False True True True True True True False True \n",
      " Test:  0.225844     Train:  0.120647 \n",
      "=======================\n",
      "False False True True True True True True False False \n",
      " Test:  0.232329     Train:  0.181189 \n",
      "=======================\n",
      "False False True True True True True False True True \n",
      " Test:  0.225304     Train:  0.118096 \n",
      "=======================\n",
      "False False True True True True True False True False \n",
      " Test:  0.220028     Train:  0.160831 \n",
      "=======================\n",
      "False False True True True True True False False True \n",
      " Test:  0.225178     Train:  0.121178 \n",
      "=======================\n",
      "False False True True True True True False False False \n",
      " Test:  0.234799     Train:  0.18512 \n",
      "=======================\n",
      "False False True True True True False True True True \n",
      " Test:  0.225837     Train:  0.121154 \n",
      "=======================\n",
      "False False True True True True False True True False \n",
      " Test:  0.221652     Train:  0.163874 \n",
      "=======================\n",
      "False False True True True True False True False True \n",
      " Test:  0.225343     Train:  0.124392 \n",
      "=======================\n",
      "False False True True True True False True False False \n",
      " Test:  0.23576     Train:  0.186341 \n",
      "=======================\n",
      "False False True True True True False False True True \n",
      " Test:  0.224876     Train:  0.120824 \n",
      "=======================\n",
      "False False True True True True False False True False \n",
      " Test:  0.221347     Train:  0.163844 \n",
      "=======================\n",
      "False False True True True True False False False True \n",
      " Test:  0.224054     Train:  0.123973 \n",
      "=======================\n",
      "False False True True True True False False False False \n",
      " Test:  0.238184     Train:  0.191221 \n",
      "=======================\n",
      "False False True True True False True True True True \n",
      " Test:  0.226493     Train:  0.120178 \n",
      "=======================\n",
      "False False True True True False True True True False \n",
      " Test:  0.220903     Train:  0.162182 \n",
      "=======================\n",
      "False False True True True False True True False True \n",
      " Test:  0.224679     Train:  0.122629 \n",
      "=======================\n",
      "False False True True True False True True False False \n",
      " Test:  0.233392     Train:  0.182731 \n",
      "=======================\n",
      "False False True True True False True False True True \n",
      " Test:  0.224776     Train:  0.120166 \n",
      "=======================\n",
      "False False True True True False True False True False \n",
      " Test:  0.221209     Train:  0.162162 \n",
      "=======================\n",
      "False False True True True False True False False True \n",
      " Test:  0.224782     Train:  0.122622 \n",
      "=======================\n",
      "False False True True True False True False False False \n",
      " Test:  0.235901     Train:  0.186827 \n",
      "=======================\n",
      "False False True True True False False True True True \n",
      " Test:  0.227012     Train:  0.121134 \n",
      "=======================\n",
      "False False True True True False False True True False \n",
      " Test:  0.221793     Train:  0.164599 \n",
      "=======================\n",
      "False False True True True False False True False True \n",
      " Test:  0.22425     Train:  0.125529 \n",
      "=======================\n",
      "False False True True True False False True False False \n",
      " Test:  0.237267     Train:  0.188216 \n",
      "=======================\n",
      "False False True True True False False False True True \n",
      " Test:  0.226255     Train:  0.121603 \n",
      "=======================\n",
      "False False True True True False False False True False \n",
      " Test:  0.221603     Train:  0.165057 \n",
      "=======================\n",
      "False False True True True False False False False True \n",
      " Test:  0.224233     Train:  0.126798 \n",
      "=======================\n",
      "False False True True True False False False False False \n",
      " Test:  0.239733     Train:  0.193506 \n",
      "=======================\n",
      "False False True True False True True True True True \n",
      " Test:  0.22496     Train:  0.121408 \n",
      "=======================\n",
      "False False True True False True True True True False \n",
      " Test:  0.220432     Train:  0.163739 \n",
      "=======================\n",
      "False False True True False True True True False True \n",
      " Test:  0.223689     Train:  0.124402 \n",
      "=======================\n",
      "False False True True False True True True False False \n",
      " Test:  0.234302     Train:  0.186334 \n",
      "=======================\n",
      "False False True True False True True False True True \n",
      " Test:  0.224764     Train:  0.121575 \n",
      "=======================\n",
      "False False True True False True True False True False \n",
      " Test:  0.220555     Train:  0.164337 \n",
      "=======================\n",
      "False False True True False True True False False True \n",
      " Test:  0.224146     Train:  0.124763 \n",
      "=======================\n",
      "False False True True False True True False False False \n",
      " Test:  0.236567     Train:  0.191614 \n",
      "=======================\n",
      "False False True True False True False True True True \n",
      " Test:  0.225074     Train:  0.124522 \n",
      "=======================\n",
      "False False True True False True False True True False \n",
      " Test:  0.222223     Train:  0.167555 \n",
      "=======================\n",
      "False False True True False True False True False True \n",
      " Test:  0.224002     Train:  0.127452 \n",
      "=======================\n",
      "False False True True False True False True False False \n",
      " Test:  0.239183     Train:  0.192912 \n",
      "=======================\n",
      "False False True True False True False False True True \n",
      " Test:  0.224818     Train:  0.125726 \n",
      "=======================\n",
      "False False True True False True False False True False \n",
      " Test:  0.221561     Train:  0.167947 \n",
      "=======================\n",
      "False False True True False True False False False True \n",
      " Test:  0.222471     Train:  0.127798 \n",
      "=======================\n",
      "False False True True False True False False False False \n",
      " Test:  0.241689     Train:  0.199255 \n",
      "=======================\n",
      "False False True True False False True True True True \n",
      " Test:  0.225451     Train:  0.123296 \n",
      "=======================\n",
      "False False True True False False True True True False \n",
      " Test:  0.221498     Train:  0.165528 \n",
      "=======================\n",
      "False False True True False False True True False True \n",
      " Test:  0.222834     Train:  0.126391 \n",
      "=======================\n",
      "False False True True False False True True False False \n",
      " Test:  0.23563     Train:  0.188021 \n",
      "=======================\n",
      "False False True True False False True False True True \n",
      " Test:  0.225013     Train:  0.123622 \n",
      "=======================\n",
      "False False True True False False True False True False \n",
      " Test:  0.221921     Train:  0.165641 \n",
      "=======================\n",
      "False False True True False False True False False True \n",
      " Test:  0.223822     Train:  0.126402 \n",
      "=======================\n",
      "False False True True False False True False False False \n",
      " Test:  0.237983     Train:  0.193469 \n",
      "=======================\n",
      "False False True True False False False True True True \n",
      " Test:  0.225585     Train:  0.124567 \n",
      "=======================\n",
      "False False True True False False False True True False \n",
      " Test:  0.22227     Train:  0.168576 \n",
      "=======================\n",
      "False False True True False False False True False True \n",
      " Test:  0.223253     Train:  0.128767 \n",
      "=======================\n",
      "False False True True False False False True False False \n",
      " Test:  0.240473     Train:  0.195018 \n",
      "=======================\n",
      "False False True True False False False False True True \n",
      " Test:  0.226028     Train:  0.125017 \n",
      "=======================\n",
      "False False True True False False False False True False \n",
      " Test:  0.222762     Train:  0.168864 \n",
      "=======================\n",
      "False False True True False False False False False True \n",
      " Test:  0.224326     Train:  0.12893 \n",
      "=======================\n",
      "False False True True False False False False False False \n",
      " Test:  0.243227     Train:  0.20169 \n",
      "=======================\n",
      "False False True False True True True True True True \n",
      " Test:  0.226709     Train:  0.118624 \n",
      "=======================\n",
      "False False True False True True True True True False \n",
      " Test:  0.220279     Train:  0.161568 \n",
      "=======================\n",
      "False False True False True True True True False True \n",
      " Test:  0.224202     Train:  0.121632 \n",
      "=======================\n",
      "False False True False True True True True False False \n",
      " Test:  0.232767     Train:  0.18229 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False True False True True True False True True \n",
      " Test:  0.226008     Train:  0.118769 \n",
      "=======================\n",
      "False False True False True True True False True False \n",
      " Test:  0.220859     Train:  0.161831 \n",
      "=======================\n",
      "False False True False True True True False False True \n",
      " Test:  0.2254     Train:  0.122285 \n",
      "=======================\n",
      "False False True False True True True False False False \n",
      " Test:  0.235154     Train:  0.186407 \n",
      "=======================\n",
      "False False True False True True False True True True \n",
      " Test:  0.225819     Train:  0.120573 \n",
      "=======================\n",
      "False False True False True True False True True False \n",
      " Test:  0.221568     Train:  0.164285 \n",
      "=======================\n",
      "False False True False True True False True False True \n",
      " Test:  0.225399     Train:  0.124829 \n",
      "=======================\n",
      "False False True False True True False True False False \n",
      " Test:  0.236554     Train:  0.187769 \n",
      "=======================\n",
      "False False True False True True False False True True \n",
      " Test:  0.225663     Train:  0.121544 \n",
      "=======================\n",
      "False False True False True True False False True False \n",
      " Test:  0.221483     Train:  0.164722 \n",
      "=======================\n",
      "False False True False True True False False False True \n",
      " Test:  0.223572     Train:  0.124081 \n",
      "=======================\n",
      "False False True False True True False False False False \n",
      " Test:  0.238874     Train:  0.192951 \n",
      "=======================\n",
      "False False True False True False True True True True \n",
      " Test:  0.226028     Train:  0.119878 \n",
      "=======================\n",
      "False False True False True False True True True False \n",
      " Test:  0.221068     Train:  0.162598 \n",
      "=======================\n",
      "False False True False True False True True False True \n",
      " Test:  0.224406     Train:  0.12367 \n",
      "=======================\n",
      "False False True False True False True True False False \n",
      " Test:  0.234013     Train:  0.183789 \n",
      "=======================\n",
      "False False True False True False True False True True \n",
      " Test:  0.225506     Train:  0.119855 \n",
      "=======================\n",
      "False False True False True False True False True False \n",
      " Test:  0.221358     Train:  0.162849 \n",
      "=======================\n",
      "False False True False True False True False False True \n",
      " Test:  0.223417     Train:  0.123791 \n",
      "=======================\n",
      "False False True False True False True False False False \n",
      " Test:  0.236251     Train:  0.18809 \n",
      "=======================\n",
      "False False True False True False False True True True \n",
      " Test:  0.225345     Train:  0.122222 \n",
      "=======================\n",
      "False False True False True False False True True False \n",
      " Test:  0.222705     Train:  0.165762 \n",
      "=======================\n",
      "False False True False True False False True False True \n",
      " Test:  0.224551     Train:  0.126474 \n",
      "=======================\n",
      "False False True False True False False True False False \n",
      " Test:  0.238089     Train:  0.189756 \n",
      "=======================\n",
      "False False True False True False False False True True \n",
      " Test:  0.22654     Train:  0.122886 \n",
      "=======================\n",
      "False False True False True False False False True False \n",
      " Test:  0.222317     Train:  0.166026 \n",
      "=======================\n",
      "False False True False True False False False False True \n",
      " Test:  0.225106     Train:  0.126464 \n",
      "=======================\n",
      "False False True False True False False False False False \n",
      " Test:  0.240492     Train:  0.195312 \n",
      "=======================\n",
      "False False True False False True True True True True \n",
      " Test:  0.224633     Train:  0.122542 \n",
      "=======================\n",
      "False False True False False True True True True False \n",
      " Test:  0.221015     Train:  0.164961 \n",
      "=======================\n",
      "False False True False False True True True False True \n",
      " Test:  0.222611     Train:  0.125817 \n",
      "=======================\n",
      "False False True False False True True True False False \n",
      " Test:  0.235368     Train:  0.187834 \n",
      "=======================\n",
      "False False True False False True True False True True \n",
      " Test:  0.224026     Train:  0.122499 \n",
      "=======================\n",
      "False False True False False True True False True False \n",
      " Test:  0.221182     Train:  0.165117 \n",
      "=======================\n",
      "False False True False False True True False False True \n",
      " Test:  0.225322     Train:  0.12554 \n",
      "=======================\n",
      "False False True False False True True False False False \n",
      " Test:  0.237445     Train:  0.193442 \n",
      "=======================\n",
      "False False True False False True False True True True \n",
      " Test:  0.225254     Train:  0.12557 \n",
      "=======================\n",
      "False False True False False True False True True False \n",
      " Test:  0.22188     Train:  0.168687 \n",
      "=======================\n",
      "False False True False False True False True False True \n",
      " Test:  0.224226     Train:  0.129338 \n",
      "=======================\n",
      "False False True False False True False True False False \n",
      " Test:  0.24024     Train:  0.194923 \n",
      "=======================\n",
      "False False True False False True False False True True \n",
      " Test:  0.225881     Train:  0.125669 \n",
      "=======================\n",
      "False False True False False True False False True False \n",
      " Test:  0.222035     Train:  0.169231 \n",
      "=======================\n",
      "False False True False False True False False False True \n",
      " Test:  0.222718     Train:  0.13027 \n",
      "=======================\n",
      "False False True False False True False False False False \n",
      " Test:  0.242778     Train:  0.20126 \n",
      "=======================\n",
      "False False True False False False True True True True \n",
      " Test:  0.225566     Train:  0.122586 \n",
      "=======================\n",
      "False False True False False False True True True False \n",
      " Test:  0.221416     Train:  0.166325 \n",
      "=======================\n",
      "False False True False False False True True False True \n",
      " Test:  0.223126     Train:  0.125967 \n",
      "=======================\n",
      "False False True False False False True True False False \n",
      " Test:  0.236509     Train:  0.189513 \n",
      "=======================\n",
      "False False True False False False True False True True \n",
      " Test:  0.226011     Train:  0.123049 \n",
      "=======================\n",
      "False False True False False False True False True False \n",
      " Test:  0.221743     Train:  0.166417 \n",
      "=======================\n",
      "False False True False False False True False False True \n",
      " Test:  0.222332     Train:  0.126882 \n",
      "=======================\n",
      "False False True False False False True False False False \n",
      " Test:  0.238494     Train:  0.195141 \n",
      "=======================\n",
      "False False True False False False False True True True \n",
      " Test:  0.224751     Train:  0.126759 \n",
      "=======================\n",
      "False False True False False False False True True False \n",
      " Test:  0.222663     Train:  0.169985 \n",
      "=======================\n",
      "False False True False False False False True False True \n",
      " Test:  0.224498     Train:  0.129821 \n",
      "=======================\n",
      "False False True False False False False True False False \n",
      " Test:  0.241725     Train:  0.197001 \n",
      "=======================\n",
      "False False True False False False False False True True \n",
      " Test:  0.22773     Train:  0.126329 \n",
      "=======================\n",
      "False False True False False False False False True False \n",
      " Test:  0.223183     Train:  0.17031 \n",
      "=======================\n",
      "False False True False False False False False False True \n",
      " Test:  0.224077     Train:  0.129919 \n",
      "=======================\n",
      "False False True False False False False False False False \n",
      " Test:  0.244603     Train:  0.204254 \n",
      "=======================\n",
      "False False False True True True True True True True \n",
      " Test:  0.231443     Train:  0.139647 \n",
      "=======================\n",
      "False False False True True True True True True False \n",
      " Test:  0.235116     Train:  0.186315 \n",
      "=======================\n",
      "False False False True True True True True False True \n",
      " Test:  0.230773     Train:  0.144486 \n",
      "=======================\n",
      "False False False True True True True True False False \n",
      " Test:  0.263932     Train:  0.220359 \n",
      "=======================\n",
      "False False False True True True True False True True \n",
      " Test:  0.231732     Train:  0.140226 \n",
      "=======================\n",
      "False False False True True True True False True False \n",
      " Test:  0.235502     Train:  0.187364 \n",
      "=======================\n",
      "False False False True True True True False False True \n",
      " Test:  0.230564     Train:  0.144243 \n",
      "=======================\n",
      "False False False True True True True False False False \n",
      " Test:  0.267758     Train:  0.227717 \n",
      "=======================\n",
      "False False False True True True False True True True \n",
      " Test:  0.231204     Train:  0.142282 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False True True True False True True False \n",
      " Test:  0.237151     Train:  0.190869 \n",
      "=======================\n",
      "False False False True True True False True False True \n",
      " Test:  0.232745     Train:  0.146462 \n",
      "=======================\n",
      "False False False True True True False True False False \n",
      " Test:  0.280687     Train:  0.241118 \n",
      "=======================\n",
      "False False False True True True False False True True \n",
      " Test:  0.229943     Train:  0.14272 \n",
      "=======================\n",
      "False False False True True True False False True False \n",
      " Test:  0.237516     Train:  0.191684 \n",
      "=======================\n",
      "False False False True True True False False False True \n",
      " Test:  0.231109     Train:  0.147232 \n",
      "=======================\n",
      "False False False True True True False False False False \n",
      " Test:  0.28941     Train:  0.255016 \n",
      "=======================\n",
      "False False False True True False True True True True \n",
      " Test:  0.23285     Train:  0.141142 \n",
      "=======================\n",
      "False False False True True False True True True False \n",
      " Test:  0.236112     Train:  0.188435 \n",
      "=======================\n",
      "False False False True True False True True False True \n",
      " Test:  0.231132     Train:  0.144727 \n",
      "=======================\n",
      "False False False True True False True True False False \n",
      " Test:  0.267251     Train:  0.224652 \n",
      "=======================\n",
      "False False False True True False True False True True \n",
      " Test:  0.231083     Train:  0.141092 \n",
      "=======================\n",
      "False False False True True False True False True False \n",
      " Test:  0.237354     Train:  0.188881 \n",
      "=======================\n",
      "False False False True True False True False False True \n",
      " Test:  0.231301     Train:  0.145016 \n",
      "=======================\n",
      "False False False True True False True False False False \n",
      " Test:  0.27156     Train:  0.232784 \n",
      "=======================\n",
      "False False False True True False False True True True \n",
      " Test:  0.231927     Train:  0.144219 \n",
      "=======================\n",
      "False False False True True False False True True False \n",
      " Test:  0.239188     Train:  0.19309 \n",
      "=======================\n",
      "False False False True True False False True False True \n",
      " Test:  0.232034     Train:  0.147906 \n",
      "=======================\n",
      "False False False True True False False True False False \n",
      " Test:  0.288045     Train:  0.24986 \n",
      "=======================\n",
      "False False False True True False False False True True \n",
      " Test:  0.231372     Train:  0.143988 \n",
      "=======================\n",
      "False False False True True False False False True False \n",
      " Test:  0.238877     Train:  0.19362 \n",
      "=======================\n",
      "False False False True True False False False False True \n",
      " Test:  0.231333     Train:  0.148608 \n",
      "=======================\n",
      "False False False True True False False False False False \n",
      " Test:  0.298749     Train:  0.265827 \n",
      "=======================\n",
      "False False False True False True True True True True \n",
      " Test:  0.230922     Train:  0.14297 \n",
      "=======================\n",
      "False False False True False True True True True False \n",
      " Test:  0.237642     Train:  0.191344 \n",
      "=======================\n",
      "False False False True False True True True False True \n",
      " Test:  0.23022     Train:  0.148012 \n",
      "=======================\n",
      "False False False True False True True True False False \n",
      " Test:  0.276083     Train:  0.237223 \n",
      "=======================\n",
      "False False False True False True True False True True \n",
      " Test:  0.231135     Train:  0.143198 \n",
      "=======================\n",
      "False False False True False True True False True False \n",
      " Test:  0.23767     Train:  0.191783 \n",
      "=======================\n",
      "False False False True False True True False False True \n",
      " Test:  0.231482     Train:  0.148356 \n",
      "=======================\n",
      "False False False True False True True False False False \n",
      " Test:  0.282982     Train:  0.24909 \n",
      "=======================\n",
      "False False False True False True False True True True \n",
      " Test:  0.232107     Train:  0.146023 \n",
      "=======================\n",
      "False False False True False True False True True False \n",
      " Test:  0.241057     Train:  0.197771 \n",
      "=======================\n",
      "False False False True False True False True False True \n",
      " Test:  0.230621     Train:  0.150914 \n",
      "=======================\n",
      "False False False True False True False True False False \n",
      " Test:  0.303354     Train:  0.268992 \n",
      "=======================\n",
      "False False False True False True False False True True \n",
      " Test:  0.231321     Train:  0.14629 \n",
      "=======================\n",
      "False False False True False True False False True False \n",
      " Test:  0.240667     Train:  0.198157 \n",
      "=======================\n",
      "False False False True False True False False False True \n",
      " Test:  0.230201     Train:  0.150853 \n",
      "=======================\n",
      "False False False True False True False False False False \n",
      " Test:  0.317764     Train:  0.288986 \n",
      "=======================\n",
      "False False False True False False True True True True \n",
      " Test:  0.233289     Train:  0.145328 \n",
      "=======================\n",
      "False False False True False False True True True False \n",
      " Test:  0.238538     Train:  0.193369 \n",
      "=======================\n",
      "False False False True False False True True False True \n",
      " Test:  0.23208     Train:  0.149194 \n",
      "=======================\n",
      "False False False True False False True True False False \n",
      " Test:  0.281568     Train:  0.243662 \n",
      "=======================\n",
      "False False False True False False True False True True \n",
      " Test:  0.22984     Train:  0.145547 \n",
      "=======================\n",
      "False False False True False False True False True False \n",
      " Test:  0.238859     Train:  0.194163 \n",
      "=======================\n",
      "False False False True False False True False False True \n",
      " Test:  0.229996     Train:  0.149672 \n",
      "=======================\n",
      "False False False True False False True False False False \n",
      " Test:  0.289998     Train:  0.257317 \n",
      "=======================\n",
      "False False False True False False False True True True \n",
      " Test:  0.231601     Train:  0.148423 \n",
      "=======================\n",
      "False False False True False False False True True False \n",
      " Test:  0.241343     Train:  0.199231 \n",
      "=======================\n",
      "False False False True False False False True False True \n",
      " Test:  0.232315     Train:  0.151979 \n",
      "=======================\n",
      "False False False True False False False True False False \n",
      " Test:  0.311423     Train:  0.27855 \n",
      "=======================\n",
      "False False False True False False False False True True \n",
      " Test:  0.232929     Train:  0.148334 \n",
      "=======================\n",
      "False False False True False False False False True False \n",
      " Test:  0.241577     Train:  0.199926 \n",
      "=======================\n",
      "False False False True False False False False False True \n",
      " Test:  0.230589     Train:  0.152019 \n",
      "=======================\n",
      "False False False True False False False False False False \n",
      " Test:  0.326578     Train:  0.29926 \n",
      "=======================\n",
      "False False False False True True True True True True \n",
      " Test:  0.230257     Train:  0.141335 \n",
      "=======================\n",
      "False False False False True True True True True False \n",
      " Test:  0.235615     Train:  0.187579 \n",
      "=======================\n",
      "False False False False True True True True False True \n",
      " Test:  0.230354     Train:  0.14526 \n",
      "=======================\n",
      "False False False False True True True True False False \n",
      " Test:  0.266318     Train:  0.223738 \n",
      "=======================\n",
      "False False False False True True True False True True \n",
      " Test:  0.229755     Train:  0.140856 \n",
      "=======================\n",
      "False False False False True True True False True False \n",
      " Test:  0.235451     Train:  0.188367 \n",
      "=======================\n",
      "False False False False True True True False False True \n",
      " Test:  0.230648     Train:  0.145118 \n",
      "=======================\n",
      "False False False False True True True False False False \n",
      " Test:  0.2705     Train:  0.231735 \n",
      "=======================\n",
      "False False False False True True False True True True \n",
      " Test:  0.232287     Train:  0.143335 \n",
      "=======================\n",
      "False False False False True True False True True False \n",
      " Test:  0.238013     Train:  0.192941 \n",
      "=======================\n",
      "False False False False True True False True False True \n",
      " Test:  0.231404     Train:  0.147901 \n",
      "=======================\n",
      "False False False False True True False True False False \n",
      " Test:  0.286024     Train:  0.247753 \n",
      "=======================\n",
      "False False False False True True False False True True \n",
      " Test:  0.231168     Train:  0.143845 \n",
      "=======================\n",
      "False False False False True True False False True False \n",
      " Test:  0.238883     Train:  0.193869 \n",
      "=======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False False True True False False False True \n",
      " Test:  0.230367     Train:  0.14844 \n",
      "=======================\n",
      "False False False False True True False False False False \n",
      " Test:  0.296203     Train:  0.263183 \n",
      "=======================\n",
      "False False False False True False True True True True \n",
      " Test:  0.231902     Train:  0.141567 \n",
      "=======================\n",
      "False False False False True False True True True False \n",
      " Test:  0.237143     Train:  0.18939 \n",
      "=======================\n",
      "False False False False True False True True False True \n",
      " Test:  0.230652     Train:  0.146648 \n",
      "=======================\n",
      "False False False False True False True True False False \n",
      " Test:  0.269956     Train:  0.228537 \n",
      "=======================\n",
      "False False False False True False True False True True \n",
      " Test:  0.232016     Train:  0.142263 \n",
      "=======================\n",
      "False False False False True False True False True False \n",
      " Test:  0.237318     Train:  0.189891 \n",
      "=======================\n",
      "False False False False True False True False False True \n",
      " Test:  0.231097     Train:  0.146525 \n",
      "=======================\n",
      "False False False False True False True False False False \n",
      " Test:  0.27495     Train:  0.237628 \n",
      "=======================\n",
      "False False False False True False False True True True \n",
      " Test:  0.23139     Train:  0.144942 \n",
      "=======================\n",
      "False False False False True False False True True False \n",
      " Test:  0.239335     Train:  0.194691 \n",
      "=======================\n",
      "False False False False True False False True False True \n",
      " Test:  0.229862     Train:  0.148664 \n",
      "=======================\n",
      "False False False False True False False True False False \n",
      " Test:  0.293836     Train:  0.256672 \n",
      "=======================\n",
      "False False False False True False False False True True \n",
      " Test:  0.231502     Train:  0.144676 \n",
      "=======================\n",
      "False False False False True False False False True False \n",
      " Test:  0.23956     Train:  0.195392 \n",
      "=======================\n",
      "False False False False True False False False False True \n",
      " Test:  0.229197     Train:  0.149194 \n",
      "=======================\n",
      "False False False False True False False False False False \n",
      " Test:  0.306355     Train:  0.274769 \n",
      "=======================\n",
      "False False False False False True True True True True \n",
      " Test:  0.229995     Train:  0.144739 \n",
      "=======================\n",
      "False False False False False True True True True False \n",
      " Test:  0.238021     Train:  0.193206 \n",
      "=======================\n",
      "False False False False False True True True False True \n",
      " Test:  0.230339     Train:  0.148681 \n",
      "=======================\n",
      "False False False False False True True True False False \n",
      " Test:  0.280725     Train:  0.242978 \n",
      "=======================\n",
      "False False False False False True True False True True \n",
      " Test:  0.231012     Train:  0.144793 \n",
      "=======================\n",
      "False False False False False True True False True False \n",
      " Test:  0.238979     Train:  0.194147 \n",
      "=======================\n",
      "False False False False False True True False False True \n",
      " Test:  0.229929     Train:  0.148885 \n",
      "=======================\n",
      "False False False False False True True False False False \n",
      " Test:  0.28881     Train:  0.256378 \n",
      "=======================\n",
      "False False False False False True False True True True \n",
      " Test:  0.229885     Train:  0.146787 \n",
      "=======================\n",
      "False False False False False True False True True False \n",
      " Test:  0.240931     Train:  0.199053 \n",
      "=======================\n",
      "False False False False False True False True False True \n",
      " Test:  0.230355     Train:  0.152577 \n",
      "=======================\n",
      "False False False False False True False True False False \n",
      " Test:  0.309315     Train:  0.276544 \n",
      "=======================\n",
      "False False False False False True False False True True \n",
      " Test:  0.229481     Train:  0.147262 \n",
      "=======================\n",
      "False False False False False True False False True False \n",
      " Test:  0.242211     Train:  0.200165 \n",
      "=======================\n",
      "False False False False False True False False False True \n",
      " Test:  0.230461     Train:  0.152895 \n",
      "=======================\n",
      "False False False False False True False False False False \n",
      " Test:  0.323807     Train:  0.296524 \n",
      "=======================\n",
      "False False False False False False True True True True \n",
      " Test:  0.231099     Train:  0.145249 \n",
      "=======================\n",
      "False False False False False False True True True False \n",
      " Test:  0.239356     Train:  0.194581 \n",
      "=======================\n",
      "False False False False False False True True False True \n",
      " Test:  0.232159     Train:  0.149475 \n",
      "=======================\n",
      "False False False False False False True True False False \n",
      " Test:  0.286615     Train:  0.249921 \n",
      "=======================\n",
      "False False False False False False True False True True \n",
      " Test:  0.230631     Train:  0.145406 \n",
      "=======================\n",
      "False False False False False False True False True False \n",
      " Test:  0.240095     Train:  0.19559 \n",
      "=======================\n",
      "False False False False False False True False False True \n",
      " Test:  0.231708     Train:  0.14981 \n",
      "=======================\n",
      "False False False False False False True False False False \n",
      " Test:  0.29598     Train:  0.26469 \n",
      "=======================\n",
      "False False False False False False False True True True \n",
      " Test:  0.232532     Train:  0.148556 \n",
      "=======================\n",
      "False False False False False False False True True False \n",
      " Test:  0.242534     Train:  0.201361 \n",
      "=======================\n",
      "False False False False False False False True False True \n",
      " Test:  0.230876     Train:  0.153023 \n",
      "=======================\n",
      "False False False False False False False True False False \n",
      " Test:  0.317596     Train:  0.287303 \n",
      "=======================\n",
      "False False False False False False False False True True \n",
      " Test:  0.232021     Train:  0.148726 \n",
      "=======================\n",
      "False False False False False False False False True False \n",
      " Test:  0.24341     Train:  0.20242 \n",
      "=======================\n",
      "False False False False False False False False False True \n",
      " Test:  0.232735     Train:  0.153139 \n",
      "=======================\n",
      "False False False False False False False False False False \n",
      " Test:  0.33362     Train:  0.30966 \n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "for do_hist_hsv_full in [True, False]:\n",
    "    for do_hist_hsv_4_4 in [True, False]:\n",
    "        for do_hist_hsv_8_8 in [True, False]:\n",
    "            for do_mean_std_channel_8_8 in [True, False]:\n",
    "                for do_mean_std_channel_4_4 in [True, False]:\n",
    "                    for do_min_max_channel_8_8 in [True, False]:\n",
    "                        for do_min_max_channel_4_4 in [True, False]:\n",
    "                            for do_hist_channel_full in [True, False]:\n",
    "                                for do_hist_channel_8_8 in [True, False]:\n",
    "                                    for do_hist_channel_4_4 in [True, False]:\n",
    "                                        #добавляем фичи\n",
    "                                        features = {'hist_hsv_full': do_hist_hsv_full, \n",
    "                                                    'hist_hsv_4_4': do_hist_hsv_4_4, \n",
    "                                                   'hist_hsv_8_8': do_hist_hsv_8_8, \n",
    "                                                    'mean_std_channel_8_8': do_mean_std_channel_8_8,\n",
    "                                                   'mean_std_channel_4_4': do_mean_std_channel_4_4, \n",
    "                                                    'min_max_channel_8_8':do_min_max_channel_8_8,\n",
    "                                                   'min_max_channel_4_4': do_min_max_channel_4_4, \n",
    "                                                    'hist_channel_full': do_hist_channel_full,\n",
    "                                                    'hist_channel_8_8': do_hist_channel_8_8,\n",
    "                                                    'hist_channel_4_4': do_hist_channel_4_4\n",
    "                                                   }\n",
    "                                        \n",
    "                                        new_data = add_features_data(features)\n",
    "                                        \n",
    "                                        #разбиваем на обучающую и тестовую(валидационную) выборку\n",
    "                                        train_data = new_data[:8000]\n",
    "                                        train_labels = labels[:8000]\n",
    "                                        test_data = new_data[8000:]\n",
    "                                        test_labels = labels[8000:]\n",
    "                                        rmse_test, rmse_train = normalize_fit_rmse(train_data, train_labels, \n",
    "                                                                                   test_data, test_labels)\n",
    "                                        \n",
    "                                        result = [do_hist_hsv_full, do_hist_hsv_4_4, do_hist_hsv_8_8, \n",
    "                                                  do_mean_std_channel_8_8, do_mean_std_channel_4_4, do_min_max_channel_8_8, \n",
    "                                                  do_min_max_channel_4_4, do_hist_channel_full, do_hist_channel_8_8,\n",
    "                                                  do_hist_channel_4_4, rmse_test, rmse_train]\n",
    "                                        rmses.append(result)\n",
    "                                        print(do_hist_hsv_full, do_hist_hsv_4_4, do_hist_hsv_8_8,do_mean_std_channel_8_8,\n",
    "                                                  do_mean_std_channel_4_4, do_min_max_channel_8_8, \n",
    "                                                  do_min_max_channel_4_4, do_hist_channel_full, do_hist_channel_8_8,\n",
    "                                                  do_hist_channel_4_4, '\\n Test: ', round(rmse_test, 6),\n",
    "                                              '    Train: ', round(rmse_train, 6), '\\n=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из лучших результатов получилось rmse у модели со всеми фичами. Также неплохой результат имеют и ряд других моделей. Одна из них - модель со всеми фичами, кроме двух (min_max_channel_4_4 и hist_channel_8_8). Далее будем рассматривать эти 2 модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делаем то же самое для всей выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучимся на всех размеченных данных и предскажем ответы для неразмеченных <br>\n",
    "Обучим сразу 2 модели с разным набором фич, которые дали неплохие результаты на валидационной выборке, а потом усредним их ответы. <br>\n",
    "В качестве этих 2ух моделей возьмем модель со всеми фичами без двух (min_max_channel_4_4 и hist_channel_8_8) и модель со всеми фичами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучаем первую модель**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "переводим data и test_images в фичи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = {'hist_hsv_full': 1, \n",
    "                                                    'hist_hsv_4_4': 1, \n",
    "                                                   'hist_hsv_8_8': 1, \n",
    "                                                    'mean_std_channel_8_8': 1,\n",
    "                                                   'mean_std_channel_4_4': 1, \n",
    "                                                    'min_max_channel_8_8':1,\n",
    "                                                   'min_max_channel_4_4': 0, \n",
    "                                                    'hist_channel_full': 1,\n",
    "                                                    'hist_channel_8_8': 0,\n",
    "                                                    'hist_channel_4_4': 1\n",
    "                                                   }\n",
    "new_data = add_features_data(features)\n",
    "new_test = add_features_test(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#масштабируем \n",
    "mean = np.mean(new_data)\n",
    "std = np.std(new_data)\n",
    "train_data_scaled = (new_data - mean) / std\n",
    "test_data_scaled = (new_test - mean) / std\n",
    "\n",
    "#размеры матриц\n",
    "D = train_data_scaled.shape[1]\n",
    "N = train_data_scaled.shape[0]\n",
    "C = 2\n",
    "\n",
    "np.random.seed(100)\n",
    "#инициализируем матрицу весов\n",
    "W = np.random.randn(D, C) * 0.01\n",
    "\n",
    "#для имитации вектора b добавляем к матрицам W и X (train_data_scaled) по дополнительному вектору\n",
    "W = np.concatenate((W, np.zeros((1, C))))\n",
    "train_data_scaled = np.concatenate((train_data_scaled, np.ones((N, 1))), axis=1)\n",
    "test_data_scaled = np.concatenate((test_data_scaled, np.ones((test_data_scaled.shape[0], 1))), axis=1)\n",
    "\n",
    "#обучение\n",
    "n_iter = 900\n",
    "W_res = gradientDescentAdam(W.copy(), train_data_scaled, labels, n_iter, penalty='l1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучаем вторую модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = {'hist_hsv_full': 1, \n",
    "                                                    'hist_hsv_4_4': 1, \n",
    "                                                   'hist_hsv_8_8': 1, \n",
    "                                                    'mean_std_channel_8_8': 1,\n",
    "                                                   'mean_std_channel_4_4': 1, \n",
    "                                                    'min_max_channel_8_8':1,\n",
    "                                                   'min_max_channel_4_4': 1, \n",
    "                                                    'hist_channel_full': 1,\n",
    "                                                    'hist_channel_8_8': 1,\n",
    "                                                    'hist_channel_4_4': 1\n",
    "                                                   }\n",
    "new_data_2 = add_features_data(features)\n",
    "new_test_2 = add_features_test(features)\n",
    "\n",
    "#масштабируем \n",
    "mean = np.mean(new_data_2)\n",
    "std = np.std(new_data_2)\n",
    "train_data_scaled_2 = (new_data_2 - mean) / std\n",
    "test_data_scaled_2 = (new_test_2 - mean) / std\n",
    "\n",
    "#размеры матриц\n",
    "D = train_data_scaled_2.shape[1]\n",
    "N = train_data_scaled_2.shape[0]\n",
    "C = 2\n",
    "\n",
    "np.random.seed(10)\n",
    "#инициализируем матрицу весов\n",
    "W = np.random.randn(D, C) * 0.01\n",
    "\n",
    "#для имитации вектора b добавляем к матрицам W и X (train_data_scaled) по дополнительному вектору\n",
    "W = np.concatenate((W, np.zeros((1, C))))\n",
    "train_data_scaled_2 = np.concatenate((train_data_scaled_2, np.ones((N, 1))), axis=1)\n",
    "test_data_scaled_2 = np.concatenate((test_data_scaled_2, np.ones((test_data_scaled_2.shape[0], 1))), axis=1)\n",
    "\n",
    "#обучение\n",
    "n_iter = 900\n",
    "W_res_2 = gradientDescentAdam(W.copy(), train_data_scaled_2, labels, n_iter, penalty='l1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на предсказанный результат - вероятности принадлежности к каждому из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.91334386e-01,   8.66561432e-03],\n",
       "       [  9.99953307e-01,   4.66931621e-05],\n",
       "       [  9.99120677e-01,   8.79322819e-04],\n",
       "       ..., \n",
       "       [  3.00676079e-04,   9.99699324e-01],\n",
       "       [  9.99978321e-01,   2.16788159e-05],\n",
       "       [  9.99854257e-01,   1.45743135e-04]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_mean = (softmax(test_data_scaled.dot(W_res)) + softmax(test_data_scaled_2.dot(W_res_2))) / 2\n",
    "predictions_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного изменим предсказания. Если наш классификатор сильно уверен в своем выборе (принадлежность к классу >0.98 или < 0.02), то мы можем заменить эти значения на 1 и 0 соответственно. (Такие границы являются оптимальными как написано в нескольких источниках в интернете)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_mean[predictions_mean > 0.98] = 1\n",
    "predictions_mean[predictions_mean < 0.02] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем вероятности принадлежности в классу indoor в DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.859907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       res\n",
       "0   0  1.000000\n",
       "1   1  1.000000\n",
       "2   2  1.000000\n",
       "3   3  1.000000\n",
       "4   4  0.000000\n",
       "5   5  1.000000\n",
       "6   6  0.000000\n",
       "7   7  1.000000\n",
       "8   8  0.859907\n",
       "9   9  0.000000"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['id'] = np.arange(2960)\n",
    "df['res'] = predictions_mean[:,0]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создаем файлик с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('answers.csv',header=[\"id\", \"res\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
